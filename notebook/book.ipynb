{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "## In Google Coalbo\n",
    "1. Download this notebook\n",
    "2. Uploda to Google Coalbo\n",
    "3. Excute\n",
    "\n",
    "\n",
    "## In Local\n",
    "\n",
    "NOTICE: Required CUDA 12.2, Run on Windows 11 64bit\n",
    "1. Clone Repository\n",
    "```bash\n",
    "git clone git@github.com:rtr-x8/GNNMF-CL.git\n",
    "```\n",
    "2. Create conda environment by Anaconda Prompt\n",
    "```bash\n",
    "conda create -n GNNMF-CL python=3.11.11 -y\n",
    "conda activate GNNMF-CL\n",
    "conda install -c anaconda ipykernel -y\n",
    "python -m ipykernel install --user --name GNNMF-CL --display-name \"GNNMF-CL Env\"\n",
    "\n",
    "```\n",
    "3. Select Conda Environment in your Edirot(ex. VSCODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "# expect Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Once\n",
    "\"\"\"\n",
    "!pip uninstall torch -y\n",
    "!pip install -q --no-cache-dir torch==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse pyg-lib torch-geometric torchvision -y\n",
    "!pip install -q --no-cache-dir torch-geometric\n",
    "!pip install -q --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q --no-cache-dir torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q --no-cache-dir install torchmetrics\n",
    "\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install scikit-learn tqdm pandas numpy setuptools datetime pytz sentence-transformers matplotlib seaborn\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyg_lib\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if \"vingat\" in sys.modules:\n",
    "    del sys.modules[\"vingat\"]\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vingat.logger import get_run_name, log_metrics\n",
    "from vingat.assertion import assert_package_versions\n",
    "from vingat.loader import (\n",
    "    core_file_loader, load_recipe_nutrients, load_ingredients,\n",
    "    load_recipe_ingredients, load_recipe_cooking_directions,\n",
    "    load_ingredients_with_embeddings, load_recipe_image_embeddings, load_recipe_image_embeddings_ft,\n",
    "    load_recipe_image_vlm_caption,\n",
    "    load_recipe_cooking_directions_embeddings,\n",
    "    load_recipe_image_vlm_caption_embeddings,\n",
    "    load_user_embeddings, load_alternative_ingredients,\n",
    "    train_dataclustering, calculate_cluster)\n",
    "from vingat.loss import BPRLoss\n",
    "from vingat.model import RecommendationModel\n",
    "from vingat.functions import evaluate_model, save_model, train_func, get_item_popularity\n",
    "from vingat import __version__ as vingat_version\n",
    "from vingat.dataloader import create_base_hetero, mask_hetero, create_dataloader\n",
    "from vingat.visualizer import visualize_node_pca\n",
    "from vingat.preprocess import filter_recipe_ingredient\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "assert_package_versions() # assert versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv wandb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandab_api = os.getenv('WANDB_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from vingat.loader import use_nutritions\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "PROJECT_NAME = \"vingat-v3_local\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "CONFIG = {\n",
    "    \"architecture\": \"LightGCN, HGT, GAT\",\n",
    "    \"_mode\" : \"in_local\",\n",
    "    \"batch_size\": 256,\n",
    "    \"bprloss_reg_lambda\": 0.001,\n",
    "    \"cl_loss_rate\": 0.2,\n",
    "    \"criterion\": \"\",\n",
    "    \"default_decay\": 0.00002,\n",
    "    \"device\": device,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 80,\n",
    "    \"filter_ingredient_sim_score\": 0.7,\n",
    "    \"fusion_gnn_after_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_resisual_alpha\": 0.5,\n",
    "    \"fusion_layers\": 1,\n",
    "    \"hidden_dimention\": 128,\n",
    "    \"image_encoder_low_rank_dim\": 64,\n",
    "    \"input_cooking_direction_dim\": 384,\n",
    "    \"input_image_dim\": 1024,\n",
    "    \"input_ingredient_dim\": 384,\n",
    "    \"input_vlm_caption_dim\": 384,\n",
    "    \"intention_cl_after_dropout_rate\": 0.2,\n",
    "    \"intention_layers\": 1,\n",
    "    \"item_encoder_dropout_rate\": 0.2,\n",
    "    \"item_encoder_low_rank_dim\": 64,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"link_predictor_dropout_rate\": 0.2,\n",
    "    \"link_predictor_leaky_relu_slope\": 0.3,\n",
    "    \"max_grad_norm\": 30,\n",
    "    \"multi_head\": 1,\n",
    "    \"node_embeding_dimmention\": 32,\n",
    "    \"nutrient_dim\": 20,\n",
    "    \"patience\": 20,  #  Early stop at least, * validation_interval\n",
    "    \"pyg_lib v\": pyg_lib.__version__,\n",
    "    \"rating_threshold\": 3.5,\n",
    "    \"scheduler_gamma\": 0.975,\n",
    "    \"scheduler_size\": 10,\n",
    "    \"seed\": 2020,\n",
    "    \"sencing_layers\": 1,\n",
    "    \"sensing_gnn_resisual_alpha\": 0.5,\n",
    "    \"taste_gnn_after_dropout_rate\": 0.2,\n",
    "    \"taste_gnn_dropout_rate\": 0.2,\n",
    "    \"temperature\": 0.1,\n",
    "    \"torch v\": torch.__version__,\n",
    "    \"torch_geometric v\": torch_geometric.__version__,\n",
    "    \"torch_scatter v\": torch_scatter.__version__,\n",
    "    \"torch_sparse v\": torch_sparse.__version__,\n",
    "    \"user_encoder_dropout_rate\": 0.2,\n",
    "    \"user_encoder_low_rank_dim\": 64,\n",
    "    \"user_encoder_weight_decay\": 0.000001,\n",
    "    \"validation_interval\": 2,\n",
    "    \"vingat_v\": vingat_version,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "\n",
    "run_name = get_run_name()\n",
    "run_name = f\"{run_name}_{vingat_version}\"\n",
    "\n",
    "wandb.login(key=wandab_api)\n",
    "wandb.init(\n",
    "  project=PROJECT_NAME,\n",
    "  name=run_name,\n",
    "  config=CONFIG,\n",
    "  tags=[\"in_local\", \"use_mini_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n",
      "recipe_nutrients is loaded\n",
      "ingredients is loaded\n",
      "recipe_ingredients is loaded\n",
      "recipe_cooking_directions is loaded\n",
      "ingredients_with_embeddings is loaded\n",
      "recipe_image_embeddings_ft is loaded\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "\n",
    "# File loader\n",
    "core_recipes, core_train_rating, core_test_rating, core_val_rating = core_file_loader(PATH, CONFIG[\"rating_threshold\"])\n",
    "core_recipe_indices = core_recipes.index.values\n",
    "recipe_nutrients = load_recipe_nutrients(PATH, core_recipes.copy())\n",
    "ingredients = load_ingredients(PATH, core_recipes.copy())\n",
    "alternative_ingredients = load_alternative_ingredients(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_ingredients = load_recipe_ingredients(PATH, core_recipes.copy())\n",
    "recipe_cooking_directions = load_recipe_cooking_directions(PATH, core_recipes.copy())\n",
    "ingredients_with_embeddings = load_ingredients_with_embeddings(PATH, ingredients.copy())\n",
    "recipe_image_embeddings = load_recipe_image_embeddings_ft(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_image_vlm_caption = load_recipe_image_vlm_caption(PATH)\n",
    "recipe_cooking_directions_embeddings = load_recipe_cooking_directions_embeddings(PATH, recipe_cooking_directions.copy())\n",
    "recipe_ingredients = filter_recipe_ingredient(recipe_ingredients, alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "ingredients = ingredients[ingredients.index.isin(recipe_ingredients[\"ingredient_id\"])]\n",
    "recipe_image_vlm_caption_embeddings = load_recipe_image_vlm_caption_embeddings(PATH, recipe_image_vlm_caption.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['niacin', 'fiber', 'sugars', 'sodium', 'carbohydrates', 'vitaminB6',\n",
      "       'calories', 'thiamin', 'fat', 'folate', 'caloriesFromFat', 'calcium',\n",
      "       'magnesium', 'iron', 'cholesterol', 'protein', 'vitaminA', 'potassium',\n",
      "       'saturatedFat', 'vitaminC', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but KMeans was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = train_dataclustering(\n",
    "    train_data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id)][use_nutritions],\n",
    "    n_cluster=6,\n",
    "    path=PATH\n",
    ")\n",
    "\n",
    "b = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_val_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH\n",
    ")\n",
    "\n",
    "print(a.head())\n",
    "print(b.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mini data\n",
    "\"\"\"\n",
    "mini_path = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "mini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\n",
    "user_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\n",
    "recipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\n",
    "mini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\n",
    "mini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\n",
    "mini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "mini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\n",
    "mini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\n",
    "mini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\n",
    "mini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\n",
    "mini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\n",
    "mini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "mini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "\n",
    "diff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\n",
    "mini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\n",
    "\n",
    "mini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\n",
    "mini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\n",
    "mini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\n",
    "mini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\n",
    "mini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\n",
    "mini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\n",
    "mini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\n",
    "mini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\n",
    "mini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\n",
    "mini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\n",
    "mini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\n",
    "mini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\n",
    "mini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\n",
    "mini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, user_lencoder, item_lencoder, ing_lencoder = create_base_hetero(\n",
    "    core_train_rating=core_train_rating,\n",
    "    core_test_rating=core_test_rating,\n",
    "    core_val_rating=core_val_rating,\n",
    "    ingredients=ingredients,\n",
    "    recipe_nutrients=recipe_nutrients,\n",
    "    recipe_image_embeddings=recipe_image_embeddings,\n",
    "    recipe_image_vlm_caption_embeddings=recipe_image_vlm_caption_embeddings,\n",
    "    recipe_cooking_directions_embeddings=recipe_cooking_directions_embeddings,\n",
    "    ingredients_with_embeddings=ingredients_with_embeddings,\n",
    "    directory_path=PATH,\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    ")\n",
    "\n",
    "train_data, ss = mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=True)\n",
    "test_data, _ = mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "val_data, _ = mask_hetero(data, core_val_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "\n",
    "mini_train = test_data.clone()\n",
    "pops = get_item_popularity(device, item_lencoder, PATH, CONFIG[\"rating_threshold\"])\n",
    "\n",
    "train_loader = create_dataloader(train_data, CONFIG[\"batch_size\"], num_workers=2, neg_sampling_ratio=1.0, popularity=pops, is_abration_cl=False)\n",
    "test_loader = create_dataloader(test_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n",
    "val_loader = create_dataloader(val_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nデータ構造\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = RecommendationModel(\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    node_embeding_dimmention=CONFIG[\"node_embeding_dimmention\"],\n",
    "    num_user=len(user_lencoder.classes_),\n",
    "    num_item=len(item_lencoder.classes_),\n",
    "    nutrient_dim=CONFIG[\"nutrient_dim\"],\n",
    "    num_heads=CONFIG[\"multi_head\"],\n",
    "    sencing_layers=CONFIG[\"sencing_layers\"],\n",
    "    fusion_layers=CONFIG[\"fusion_layers\"],\n",
    "    intention_layers=CONFIG[\"intention_layers\"],\n",
    "    temperature=CONFIG[\"temperature\"],\n",
    "    cl_loss_rate=CONFIG[\"cl_loss_rate\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    "    user_encoder_low_rank_dim=CONFIG[\"user_encoder_low_rank_dim\"],\n",
    "    item_encoder_low_rank_dim=CONFIG[\"item_encoder_low_rank_dim\"],\n",
    "    user_encoder_dropout_rate=CONFIG[\"user_encoder_dropout_rate\"],\n",
    "    item_encoder_dropout_rate=CONFIG[\"item_encoder_dropout_rate\"],\n",
    "    intention_cl_after_dropout_rate=CONFIG[\"intention_cl_after_dropout_rate\"],\n",
    "    taste_gnn_dropout_rate=CONFIG[\"taste_gnn_dropout_rate\"],\n",
    "    taste_gnn_after_dropout_rate=CONFIG[\"taste_gnn_after_dropout_rate\"],\n",
    "    fusion_gnn_dropout_rate=CONFIG[\"fusion_gnn_dropout_rate\"],\n",
    "    fusion_gnn_after_dropout_rate=CONFIG[\"fusion_gnn_after_dropout_rate\"],\n",
    "    link_predictor_dropout_rate=CONFIG[\"link_predictor_dropout_rate\"],\n",
    "    link_predictor_leaky_relu_slope=CONFIG[\"link_predictor_leaky_relu_slope\"],\n",
    "    sensing_gnn_resisual_alpha=CONFIG[\"sensing_gnn_resisual_alpha\"],\n",
    "    fusion_gnn_resisual_alpha=CONFIG[\"fusion_gnn_resisual_alpha\"],\n",
    "    is_abration_wo_cl=False,\n",
    "    is_abration_wo_taste=False,\n",
    "    image_encoder_low_rank_dim=CONFIG[\"image_encoder_low_rank_dim\"],\n",
    ")\n",
    "\n",
    "user_encoder_params = list(model.user_encoder.parameters())\n",
    "other_params = [\n",
    "    p for p in model.parameters()\n",
    "    if not any(torch.equal(p.data, up.data) for up in user_encoder_params)\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": user_encoder_params,\n",
    "            \"weight_decay\": CONFIG[\"user_encoder_weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": other_params,\n",
    "            \"weight_decay\": CONFIG[\"default_decay\"],\n",
    "        }\n",
    "    ],\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    # weight_decay=CONFIG[\"default_decay\"],\n",
    ")\n",
    "\n",
    "# criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=CONFIG[\"scheduler_size\"],\n",
    "    gamma=CONFIG[\"scheduler_gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "model_summary = summary(model, verbose=0)\n",
    "\n",
    "summary_text = str(model_summary)\n",
    "summary_text = summary_text.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "wandb.log({\"model_summary\": wandb.Html(summary_text)})\n",
    "print(\"\\n\\n\\nモデルの構造\")\n",
    "print(model_summary)\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_logger(**kwargs):\n",
    "    try:\n",
    "        wandb.log(**kwargs)\n",
    "    except:\n",
    "        print(kwargs)\n",
    "        pass\n",
    "\n",
    "def wandb_tagger(*args):\n",
    "    try:\n",
    "        wandb.run.tags = list(wandb.run.tags) + list(args)\n",
    "    except:\n",
    "        print(args)\n",
    "        pass\n",
    "\n",
    "def wandb_scatter(df, step, title):\n",
    "    df[\"step\"] = step\n",
    "    table = wandb.Table(data=df, columns=[\"PC1\", \"PC2\", \"node_type\"])\n",
    "    color_cahrt = wandb.plot.scatter(\n",
    "        table,\n",
    "        \"PC1\",\n",
    "        \"PC2\",\n",
    "        title=title,\n",
    "    )\n",
    "    wandb.run.log({f\"scatter_step_{step}\": color_cahrt},\n",
    "                step=step)\n",
    "\n",
    "\n",
    "pca_cols = [\"intention\", \"taste\", \"image\"]\n",
    "\n",
    "criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "\n",
    "\n",
    "train_func(\n",
    "    train_loader,\n",
    "    val_data,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=CONFIG[\"epochs\"],\n",
    "    device=device,\n",
    "    wbLogger=wandb_logger,\n",
    "    wbTagger=wandb_tagger,\n",
    "    wbScatter=wandb_scatter,\n",
    "    directory_path=PATH,\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=run_name,\n",
    "    popularities=pops,\n",
    "    patience=CONFIG[\"patience\"],\n",
    "    validation_interval=CONFIG[\"validation_interval\"],\n",
    "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
    "    pca_cols=pca_cols,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_statics, t_mhandler = evaluate_model(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    device=CONFIG[\"device\"],\n",
    "    freq_tensor=pops,\n",
    "    desc=\"[Test]\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Score Statics: \")\n",
    "print(score_statics.log(prefix=\"test-score-statics\", num_round=4))\n",
    "wandb_logger(data=score_statics.log(prefix=\"test-score-statics\"))\n",
    "\n",
    "print(\"handler Result: \")\n",
    "print(t_mhandler.log(prefix=\"test-handler\", num_round=4))\n",
    "wandb_logger(data=t_mhandler.log(prefix=\"test-handler\", num_round=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config[\"criterion\"] = str(criterion.__class__.__name__)\n",
    "wandb.run.tags = list(wandb.run.tags) + [\"image_fine_tuned\"]\n",
    "\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"crashed\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"all_same_result\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"manual_stopped\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"over_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_satisfied\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"is_trial_model\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNMF-CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
