{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "## In Google Coalbo\n",
    "1. Download this notebook\n",
    "2. Uploda to Google Coalbo\n",
    "3. Excute\n",
    "\n",
    "\n",
    "## In Local\n",
    "\n",
    "NOTICE: Required CUDA 12.2, Run on Windows 11 64bit\n",
    "1. Clone Repository\n",
    "```bash\n",
    "git clone git@github.com:rtr-x8/GNNMF-CL.git\n",
    "```\n",
    "2. Create conda environment by Anaconda Prompt\n",
    "```bash\n",
    "conda create -n GNNMF-CL python=3.11.11 -y\n",
    "conda activate GNNMF-CL\n",
    "conda install -c anaconda ipykernel -y\n",
    "python -m ipykernel install --user --name GNNMF-CL --display-name \"GNNMF-CL Env\"\n",
    "\n",
    "```\n",
    "3. Select Conda Environment in your Edirot(ex. VSCODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "# expect Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Once\n",
    "\"\"\"\n",
    "!pip uninstall torch -y\n",
    "!pip install -q --no-cache-dir torch==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse pyg-lib torch-geometric torchvision -y\n",
    "!pip install -q --no-cache-dir torch-geometric\n",
    "!pip install -q --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q --no-cache-dir torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q --no-cache-dir install torchmetrics\n",
    "\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install scikit-learn tqdm pandas numpy setuptools datetime pytz sentence-transformers matplotlib seaborn\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyg_lib\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if \"vingat\" in sys.modules:\n",
    "    del sys.modules[\"vingat\"]\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vingat.logger import get_run_name, log_metrics\n",
    "from vingat.assertion import assert_package_versions\n",
    "from vingat.loader import (\n",
    "    core_file_loader, load_recipe_nutrients, load_ingredients,\n",
    "    load_recipe_ingredients, load_recipe_cooking_directions,\n",
    "    load_ingredients_with_embeddings, load_recipe_image_embeddings, load_recipe_image_embeddings_ft,\n",
    "    load_recipe_image_vlm_caption,\n",
    "    load_recipe_cooking_directions_embeddings,\n",
    "    load_recipe_image_vlm_caption_embeddings,\n",
    "    load_user_embeddings, load_alternative_ingredients,\n",
    "    train_dataclustering, calculate_cluster, load_clouster_centers)\n",
    "from vingat.loss import BPRLoss\n",
    "from vingat.model import RecommendationModel\n",
    "from vingat.functions import evaluate_model, save_model, train_func, get_item_popularity\n",
    "from vingat import __version__ as vingat_version\n",
    "from vingat.dataloader import create_base_hetero, mask_hetero, create_dataloader\n",
    "from vingat.visualizer import visualize_node_pca\n",
    "from vingat.preprocess import filter_recipe_ingredient\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "assert_package_versions() # assert versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv wandb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandab_api = os.getenv('WANDB_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from vingat.loader import use_nutritions\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "PROJECT_NAME = \"vingat-v3_local\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "CONFIG = {\n",
    "    \"architecture\": \"LightGCN, HGT, GAT\",\n",
    "    \"_mode\" : \"in_local\",\n",
    "    \"batch_size\": 256,\n",
    "    \"bprloss_reg_lambda\": 0.001,\n",
    "    \"cl_loss_rate\": 0.2,\n",
    "    \"criterion\": \"\",\n",
    "    \"default_decay\": 0.00002,\n",
    "    \"device\": device,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 80,\n",
    "    \"filter_ingredient_sim_score\": 0.7,\n",
    "    \"fusion_gnn_after_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_resisual_alpha\": 0.5,\n",
    "    \"fusion_layers\": 1,\n",
    "    \"hidden_dimention\": 128,\n",
    "    \"image_encoder_low_rank_dim\": 64,\n",
    "    \"input_cooking_direction_dim\": 384,\n",
    "    \"input_image_dim\": 1024,\n",
    "    \"input_ingredient_dim\": 384,\n",
    "    \"input_vlm_caption_dim\": 384,\n",
    "    \"intention_cl_after_dropout_rate\": 0.2,\n",
    "    \"intention_layers\": 1,\n",
    "    \"item_encoder_dropout_rate\": 0.2,\n",
    "    \"item_encoder_low_rank_dim\": 64,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"link_predictor_dropout_rate\": 0.2,\n",
    "    \"link_predictor_leaky_relu_slope\": 0.3,\n",
    "    \"max_grad_norm\": 30,\n",
    "    \"multi_head\": 1,\n",
    "    \"node_embeding_dimmention\": 32,\n",
    "    \"nutrient_dim\": 20,\n",
    "    \"patience\": 20,  #  Early stop at least, * validation_interval\n",
    "    \"pyg_lib v\": pyg_lib.__version__,\n",
    "    \"rating_threshold\": 3.5,\n",
    "    \"scheduler_gamma\": 0.975,\n",
    "    \"scheduler_size\": 10,\n",
    "    \"seed\": 2020,\n",
    "    \"sencing_layers\": 1,\n",
    "    \"sensing_gnn_resisual_alpha\": 0.5,\n",
    "    \"taste_gnn_after_dropout_rate\": 0.2,\n",
    "    \"taste_gnn_dropout_rate\": 0.2,\n",
    "    \"temperature\": 0.1,\n",
    "    \"torch v\": torch.__version__,\n",
    "    \"torch_geometric v\": torch_geometric.__version__,\n",
    "    \"torch_scatter v\": torch_scatter.__version__,\n",
    "    \"torch_sparse v\": torch_sparse.__version__,\n",
    "    \"user_encoder_dropout_rate\": 0.2,\n",
    "    \"user_encoder_low_rank_dim\": 64,\n",
    "    \"user_encoder_weight_decay\": 0.000001,\n",
    "    \"validation_interval\": 2,\n",
    "    \"vingat_v\": vingat_version,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "\n",
    "run_name = get_run_name()\n",
    "run_name = f\"{run_name}_{vingat_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\matsuoka\\_netrc\n",
      "wandb: Currently logged in as: ryu-2-24 (ryu-2-24-shiga-u-ac-jp) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\wandb\\run-20250317_063523-m55qy3r5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/m55qy3r5' target=\"_blank\">run-20250317-063520_0.3.25</a></strong> to <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/m55qy3r5' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/m55qy3r5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/m55qy3r5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1466e360e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandab_api)\n",
    "wandb.init(\n",
    "  project=PROJECT_NAME,\n",
    "  name=run_name,\n",
    "  config=CONFIG,\n",
    "  tags=[\"in_local\", \"use_mini_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n",
      "recipe_nutrients is loaded\n",
      "ingredients is loaded\n",
      "recipe_ingredients is loaded\n",
      "recipe_cooking_directions is loaded\n",
      "ingredients_with_embeddings is loaded\n",
      "recipe_image_embeddings_ft is loaded\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "\n",
    "# File loader\n",
    "core_recipes, core_train_rating, core_test_rating, core_val_rating = core_file_loader(PATH, CONFIG[\"rating_threshold\"])\n",
    "core_recipe_indices = core_recipes.index.values\n",
    "recipe_nutrients = load_recipe_nutrients(PATH, core_recipes.copy())\n",
    "ingredients = load_ingredients(PATH, core_recipes.copy())\n",
    "alternative_ingredients = load_alternative_ingredients(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_ingredients = load_recipe_ingredients(PATH, core_recipes.copy())\n",
    "recipe_cooking_directions = load_recipe_cooking_directions(PATH, core_recipes.copy())\n",
    "ingredients_with_embeddings = load_ingredients_with_embeddings(PATH, ingredients.copy())\n",
    "recipe_image_embeddings = load_recipe_image_embeddings_ft(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_image_vlm_caption = load_recipe_image_vlm_caption(PATH)\n",
    "recipe_cooking_directions_embeddings = load_recipe_cooking_directions_embeddings(PATH, recipe_cooking_directions.copy())\n",
    "recipe_ingredients = filter_recipe_ingredient(recipe_ingredients, alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "ingredients = ingredients[ingredients.index.isin(recipe_ingredients[\"ingredient_id\"])]\n",
    "recipe_image_vlm_caption_embeddings = load_recipe_image_vlm_caption_embeddings(PATH, recipe_image_vlm_caption.copy())\n",
    "\n",
    "train_nutrients, kmeans_model, scaler = train_dataclustering(\n",
    "    train_data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id)][use_nutritions],\n",
    "    n_cluster=6,\n",
    "    path=PATH\n",
    ")\n",
    "test_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_test_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "valid_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_val_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "recipe_nutrients = pd.concat([\n",
    "    train_nutrients, test_nutrients, valid_nutrients\n",
    "])\n",
    "print(recipe_nutrients.shape)\n",
    "recipe_nutrients = recipe_nutrients.loc[~recipe_nutrients.index.duplicated(keep='first')]\n",
    "print(recipe_nutrients.shape)\n",
    "recipe_cluster_centers = load_clouster_centers(kmeanth_model=kmeans_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create mini data\n",
    "\"\"\"\n",
    "mini_path = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "mini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\n",
    "user_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\n",
    "recipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\n",
    "mini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\n",
    "mini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\n",
    "mini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "mini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\n",
    "mini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\n",
    "mini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\n",
    "mini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\n",
    "mini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\n",
    "mini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "mini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "\n",
    "diff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\n",
    "mini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\n",
    "\n",
    "mini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\n",
    "mini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\n",
    "mini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\n",
    "mini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\n",
    "mini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\n",
    "mini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\n",
    "mini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\n",
    "mini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\n",
    "mini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\n",
    "mini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\n",
    "mini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\n",
    "mini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\n",
    "mini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\n",
    "mini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[7024, 7238, 7615, 8949, 9086, 9243, 9300, 11075, 11127, 11352, 11826, 12682, 13081, 13292, 13460, 13462, 13482, 13516, 13524, 13558, 13724, 13965, 14524, 14889, 16182, 16310, 17407, 17760, 17943, 17945, 18011, 18016, 18027, 18942, 19623, 19747, 19963, 20145, 20218, 20421, 20489, 20493, 20537, 20574, 20723, 20759, 20761, 21233, 21234, 21258, 21425, 21656, 21673, 22721, 22727, 23040, 23534, 23536, 23549, 23558, 24487, 24494, 25004, 25853, 27120, 27197, 32352, 32501, 32599, 32632, 32664, 33982, 33988, 36008, 39351, 43655, 44187, 47003, 48125, 48930, 49444, 50176, 50931, 53861, 54614, 55028, 56708, 58561, 60723, 60911, 62245, 63191, 64593, 65734, 68762, 69810, 72612, 73287, 74200, 74971, 75431, 76804, 76807, 76941, 85326, 85839, 88806, 104922, 107640, 112336, 127491, 133123, 136119, 136264, 138004, 140347, 140378, 141532, 141836, 147363, 147500, 149064, 151529, 151546, 151559, 151574, 151593, 151595, 151597, 151611, 151616, 151618, 151620, 151643, 151656, 151689, 152148, 153024, 153829, 154602, 157003, 157229, 157274, 161328, 161632, 162068, 162719, 170757, 176054, 189283, 213114, 215006, 215219, 215224, 215226, 215228, 217312, 219715, 219840, 222975, 222978, 229408, 229410, 229414, 229470, 230950, 241213] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data, user_lencoder, item_lencoder, ing_lencoder \u001b[38;5;241m=\u001b[39m create_base_hetero(\n\u001b[0;32m      2\u001b[0m     core_train_rating\u001b[38;5;241m=\u001b[39mcore_train_rating,\n\u001b[0;32m      3\u001b[0m     core_test_rating\u001b[38;5;241m=\u001b[39mcore_test_rating,\n\u001b[0;32m      4\u001b[0m     core_val_rating\u001b[38;5;241m=\u001b[39mcore_val_rating,\n\u001b[0;32m      5\u001b[0m     ingredients\u001b[38;5;241m=\u001b[39mingredients,\n\u001b[0;32m      6\u001b[0m     recipe_nutrients\u001b[38;5;241m=\u001b[39mrecipe_nutrients,\n\u001b[0;32m      7\u001b[0m     recipe_image_embeddings\u001b[38;5;241m=\u001b[39mrecipe_image_embeddings,\n\u001b[0;32m      8\u001b[0m     recipe_image_vlm_caption_embeddings\u001b[38;5;241m=\u001b[39mrecipe_image_vlm_caption_embeddings,\n\u001b[0;32m      9\u001b[0m     recipe_cooking_directions_embeddings\u001b[38;5;241m=\u001b[39mrecipe_cooking_directions_embeddings,\n\u001b[0;32m     10\u001b[0m     ingredients_with_embeddings\u001b[38;5;241m=\u001b[39mingredients_with_embeddings,\n\u001b[0;32m     11\u001b[0m     directory_path\u001b[38;5;241m=\u001b[39mPATH,\n\u001b[0;32m     12\u001b[0m     device\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dimention\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m     input_image_dim\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_image_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m     input_vlm_caption_dim\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_vlm_caption_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     16\u001b[0m     input_ingredient_dim\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ingredient_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m     input_cooking_direction_dim\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_cooking_direction_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m train_data, ss \u001b[38;5;241m=\u001b[39m mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m test_data, _ \u001b[38;5;241m=\u001b[39m mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, scalar_preprocess\u001b[38;5;241m=\u001b[39mss)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\dataloader.py:125\u001b[0m, in \u001b[0;36mcreate_base_hetero\u001b[1;34m(core_train_rating, core_test_rating, core_val_rating, ingredients, recipe_nutrients, recipe_image_embeddings, recipe_image_vlm_caption_embeddings, recipe_cooking_directions_embeddings, ingredients_with_embeddings, directory_path, device, hidden_dim, input_image_dim, input_vlm_caption_dim, input_ingredient_dim, input_cooking_direction_dim)\u001b[0m\n\u001b[0;32m    122\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(item_lencoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    123\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(item_lencoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    124\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnutrient \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m--> 125\u001b[0m     _recipe_nutrients\u001b[38;5;241m.\u001b[39mloc[item_lencoder\u001b[38;5;241m.\u001b[39mclasses_, use_nutritions]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m    126\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    127\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcluster \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m    128\u001b[0m     recipe_nutrients\u001b[38;5;241m.\u001b[39mloc[item_lencoder\u001b[38;5;241m.\u001b[39mclasses_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m    129\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong\n\u001b[0;32m    130\u001b[0m )\n\u001b[0;32m    131\u001b[0m caption_encoder \u001b[38;5;241m=\u001b[39m StaticEmbeddingLoader(recipe_image_vlm_caption_embeddings,\n\u001b[0;32m    132\u001b[0m                                         dimention\u001b[38;5;241m=\u001b[39minput_vlm_caption_dim,\n\u001b[0;32m    133\u001b[0m                                         device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexing.py:1375\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;66;03m# ugly hack for GH #836\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m-> 1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexing.py:1326\u001b[0m, in \u001b[0;36m_LocIndexer._multi_take\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[1;32m-> 1326\u001b[0m d \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1327\u001b[0m     axis: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS)\n\u001b[0;32m   1329\u001b[0m }\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(d, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;124;03mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;124;03mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;66;03m# GH 836\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m d \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m-> 1327\u001b[0m     axis: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (key, axis) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tup, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_AXIS_ORDERS)\n\u001b[0;32m   1329\u001b[0m }\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(d, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[7024, 7238, 7615, 8949, 9086, 9243, 9300, 11075, 11127, 11352, 11826, 12682, 13081, 13292, 13460, 13462, 13482, 13516, 13524, 13558, 13724, 13965, 14524, 14889, 16182, 16310, 17407, 17760, 17943, 17945, 18011, 18016, 18027, 18942, 19623, 19747, 19963, 20145, 20218, 20421, 20489, 20493, 20537, 20574, 20723, 20759, 20761, 21233, 21234, 21258, 21425, 21656, 21673, 22721, 22727, 23040, 23534, 23536, 23549, 23558, 24487, 24494, 25004, 25853, 27120, 27197, 32352, 32501, 32599, 32632, 32664, 33982, 33988, 36008, 39351, 43655, 44187, 47003, 48125, 48930, 49444, 50176, 50931, 53861, 54614, 55028, 56708, 58561, 60723, 60911, 62245, 63191, 64593, 65734, 68762, 69810, 72612, 73287, 74200, 74971, 75431, 76804, 76807, 76941, 85326, 85839, 88806, 104922, 107640, 112336, 127491, 133123, 136119, 136264, 138004, 140347, 140378, 141532, 141836, 147363, 147500, 149064, 151529, 151546, 151559, 151574, 151593, 151595, 151597, 151611, 151616, 151618, 151620, 151643, 151656, 151689, 152148, 153024, 153829, 154602, 157003, 157229, 157274, 161328, 161632, 162068, 162719, 170757, 176054, 189283, 213114, 215006, 215219, 215224, 215226, 215228, 217312, 219715, 219840, 222975, 222978, 229408, 229410, 229414, 229470, 230950, 241213] not in index'"
     ]
    }
   ],
   "source": [
    "data, user_lencoder, item_lencoder, ing_lencoder = create_base_hetero(\n",
    "    core_train_rating=core_train_rating,\n",
    "    core_test_rating=core_test_rating,\n",
    "    core_val_rating=core_val_rating,\n",
    "    ingredients=ingredients,\n",
    "    recipe_nutrients=recipe_nutrients,\n",
    "    recipe_image_embeddings=recipe_image_embeddings,\n",
    "    recipe_image_vlm_caption_embeddings=recipe_image_vlm_caption_embeddings,\n",
    "    recipe_cooking_directions_embeddings=recipe_cooking_directions_embeddings,\n",
    "    ingredients_with_embeddings=ingredients_with_embeddings,\n",
    "    directory_path=PATH,\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    ")\n",
    "\n",
    "train_data, ss = mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=True)\n",
    "test_data, _ = mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "val_data, _ = mask_hetero(data, core_val_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "\n",
    "mini_train = test_data.clone()\n",
    "pops = get_item_popularity(device, item_lencoder, PATH, CONFIG[\"rating_threshold\"])\n",
    "\n",
    "train_loader = create_dataloader(train_data, CONFIG[\"batch_size\"], num_workers=2, neg_sampling_ratio=1.0, popularity=pops, is_abration_cl=False)\n",
    "test_loader = create_dataloader(test_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n",
    "val_loader = create_dataloader(val_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "データ構造\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    num_nodes=13730,\n",
       "    user_id=[13730],\n",
       "    x=[13730, 128],\n",
       "    id=[13730],\n",
       "  },\n",
       "  item={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    x=[10241, 128],\n",
       "    id=[10241],\n",
       "  },\n",
       "  image={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    org=[10241, 1024],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  intention={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    nutrient=[13054, 20],\n",
       "    cluster=[13054],\n",
       "    caption=[10241, 384],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  taste={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    org=[10241, 384],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  ingredient={\n",
       "    num_nodes=7765,\n",
       "    ingredient_id=[7765],\n",
       "    org=[7765, 384],\n",
       "    x=[7765, 128],\n",
       "  },\n",
       "  (image, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_image, image)={ edge_index=[2, 10241] },\n",
       "  (intention, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_intention, intention)={ edge_index=[2, 10241] },\n",
       "  (taste, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_taste, taste)={ edge_index=[2, 10241] },\n",
       "  (user, buys, item)={\n",
       "    edge_index=[2, 13539],\n",
       "    edge_label=[13539],\n",
       "    edge_label_index=[2, 13539],\n",
       "  },\n",
       "  (item, bought_by, user)={ edge_index=[2, 13539] },\n",
       "  (ingredient, part_of, taste)={ edge_index=[2, 60709] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\n\\nデータ構造\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = RecommendationModel(\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    node_embeding_dimmention=CONFIG[\"node_embeding_dimmention\"],\n",
    "    num_user=len(user_lencoder.classes_),\n",
    "    num_item=len(item_lencoder.classes_),\n",
    "    nutrient_dim=CONFIG[\"nutrient_dim\"],\n",
    "    num_heads=CONFIG[\"multi_head\"],\n",
    "    sencing_layers=CONFIG[\"sencing_layers\"],\n",
    "    fusion_layers=CONFIG[\"fusion_layers\"],\n",
    "    intention_layers=CONFIG[\"intention_layers\"],\n",
    "    temperature=CONFIG[\"temperature\"],\n",
    "    cl_loss_rate=CONFIG[\"cl_loss_rate\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    "    user_encoder_low_rank_dim=CONFIG[\"user_encoder_low_rank_dim\"],\n",
    "    item_encoder_low_rank_dim=CONFIG[\"item_encoder_low_rank_dim\"],\n",
    "    user_encoder_dropout_rate=CONFIG[\"user_encoder_dropout_rate\"],\n",
    "    item_encoder_dropout_rate=CONFIG[\"item_encoder_dropout_rate\"],\n",
    "    intention_cl_after_dropout_rate=CONFIG[\"intention_cl_after_dropout_rate\"],\n",
    "    taste_gnn_dropout_rate=CONFIG[\"taste_gnn_dropout_rate\"],\n",
    "    taste_gnn_after_dropout_rate=CONFIG[\"taste_gnn_after_dropout_rate\"],\n",
    "    fusion_gnn_dropout_rate=CONFIG[\"fusion_gnn_dropout_rate\"],\n",
    "    fusion_gnn_after_dropout_rate=CONFIG[\"fusion_gnn_after_dropout_rate\"],\n",
    "    link_predictor_dropout_rate=CONFIG[\"link_predictor_dropout_rate\"],\n",
    "    link_predictor_leaky_relu_slope=CONFIG[\"link_predictor_leaky_relu_slope\"],\n",
    "    sensing_gnn_resisual_alpha=CONFIG[\"sensing_gnn_resisual_alpha\"],\n",
    "    fusion_gnn_resisual_alpha=CONFIG[\"fusion_gnn_resisual_alpha\"],\n",
    "    is_abration_wo_cl=False,\n",
    "    is_abration_wo_taste=False,\n",
    "    image_encoder_low_rank_dim=CONFIG[\"image_encoder_low_rank_dim\"],\n",
    "    cluster_centers=recipe_cluster_centers\n",
    ")\n",
    "\n",
    "user_encoder_params = list(model.user_encoder.parameters())\n",
    "other_params = [\n",
    "    p for p in model.parameters()\n",
    "    if not any(torch.equal(p.data, up.data) for up in user_encoder_params)\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": user_encoder_params,\n",
    "            \"weight_decay\": CONFIG[\"user_encoder_weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": other_params,\n",
    "            \"weight_decay\": CONFIG[\"default_decay\"],\n",
    "        }\n",
    "    ],\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    # weight_decay=CONFIG[\"default_decay\"],\n",
    ")\n",
    "\n",
    "# criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=CONFIG[\"scheduler_size\"],\n",
    "    gamma=CONFIG[\"scheduler_gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\matsuoka\\.conda\\envs\\gnnmf-cl\\lib\\site-packages (1.8.0)\n",
      "\n",
      "\n",
      "\n",
      "モデルの構造\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "RecommendationModel                           --\n",
      "├─Sequential: 1-1                             --\n",
      "│    └─Embedding: 2-1                         878,720\n",
      "│    └─Linear: 2-2                            8,320\n",
      "│    └─Dropout: 2-3                           --\n",
      "├─Sequential: 1-2                             --\n",
      "│    └─Embedding: 2-4                         655,424\n",
      "│    └─Linear: 2-5                            8,320\n",
      "│    └─Dropout: 2-6                           --\n",
      "├─LowRankLinear: 1-3                          --\n",
      "│    └─Linear: 2-7                            65,536\n",
      "│    └─Linear: 2-8                            8,320\n",
      "├─Linear: 1-4                                 49,280\n",
      "├─Linear: 1-5                                 49,280\n",
      "├─NutrientCaptionContrastiveLearning: 1-6     --\n",
      "│    └─Sequential: 2-9                        --\n",
      "│    │    └─Linear: 3-1                       1,344\n",
      "│    │    └─ReLU: 3-2                         --\n",
      "│    │    └─Linear: 3-3                       8,320\n",
      "│    └─Sequential: 2-10                       --\n",
      "│    │    └─Linear: 3-4                       98,560\n",
      "│    │    └─ReLU: 3-5                         --\n",
      "│    │    └─Linear: 3-6                       32,896\n",
      "│    └─ContrastiveLoss: 2-11                  --\n",
      "├─Sequential: 1-7                             --\n",
      "│    └─DictActivate: 2-12                     --\n",
      "│    └─DictDropout: 2-13                      --\n",
      "├─ModuleList: 1-8                             --\n",
      "│    └─TasteGNN: 2-14                         --\n",
      "│    │    └─HANConv: 3-7                      49,920\n",
      "├─Sequential: 1-9                             --\n",
      "│    └─DictActivate: 2-15                     --\n",
      "│    └─DictDropout: 2-16                      --\n",
      "├─ModuleList: 1-10                            --\n",
      "│    └─MultiModalFusionGAT: 2-17              --\n",
      "│    │    └─HGTConv: 3-8                      494,090\n",
      "├─Sequential: 1-11                            --\n",
      "│    └─DictActivate: 2-18                     --\n",
      "│    └─DictDropout: 2-19                      --\n",
      "├─Sequential: 1-12                            --\n",
      "│    └─Linear: 2-20                           32,896\n",
      "│    └─LeakyReLU: 2-21                        --\n",
      "│    └─Dropout: 2-22                          --\n",
      "│    └─Linear: 2-23                           129\n",
      "├─DictLayerNormForLayer: 1-13                 --\n",
      "│    └─ModuleDict: 2-24                       --\n",
      "│    │    └─LayerNorm: 3-9                    256\n",
      "│    │    └─LayerNorm: 3-10                   256\n",
      "│    │    └─LayerNorm: 3-11                   256\n",
      "│    │    └─LayerNorm: 3-12                   256\n",
      "│    │    └─LayerNorm: 3-13                   256\n",
      "│    │    └─LayerNorm: 3-14                   256\n",
      "│    └─ModuleDict: 2-25                       --\n",
      "│    │    └─Sequential: 3-15                  33,280\n",
      "│    │    └─Sequential: 3-16                  33,280\n",
      "│    │    └─Sequential: 3-17                  33,280\n",
      "│    │    └─Sequential: 3-18                  33,280\n",
      "│    │    └─Sequential: 3-19                  33,280\n",
      "│    │    └─Sequential: 3-20                  33,280\n",
      "======================================================================\n",
      "Total params: 2,642,571\n",
      "Trainable params: 2,642,571\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "model_summary = summary(model, verbose=0)\n",
    "\n",
    "summary_text = str(model_summary)\n",
    "summary_text = summary_text.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "wandb.log({\"model_summary\": wandb.Html(summary_text)})\n",
    "print(\"\\n\\n\\nモデルの構造\")\n",
    "print(model_summary)\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      " Epoch 1/80 2025-03-17 06:26:27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ff1c3c07ed445e86ba4bce2e03930b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "cuda:0 cuda:0\n",
      "torch.Size([13054, 128]) torch.Size([1140, 128])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([1024, 14194]) torch.Size([1024])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([1024, 14194]) torch.Size([1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m pca_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaste\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m BPRLoss(reg_lambda\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbprloss_reg_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m train_func(\n\u001b[0;32m     34\u001b[0m     train_loader,\n\u001b[0;32m     35\u001b[0m     val_data,\n\u001b[0;32m     36\u001b[0m     model,\n\u001b[0;32m     37\u001b[0m     optimizer,\n\u001b[0;32m     38\u001b[0m     scheduler,\n\u001b[0;32m     39\u001b[0m     criterion,\n\u001b[0;32m     40\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     42\u001b[0m     wbLogger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[0;32m     43\u001b[0m     wbTagger\u001b[38;5;241m=\u001b[39mwandb_tagger,\n\u001b[0;32m     44\u001b[0m     wbScatter\u001b[38;5;241m=\u001b[39mwandb_scatter,\n\u001b[0;32m     45\u001b[0m     directory_path\u001b[38;5;241m=\u001b[39mPATH,\n\u001b[0;32m     46\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mPROJECT_NAME,\n\u001b[0;32m     47\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m     48\u001b[0m     popularities\u001b[38;5;241m=\u001b[39mpops,\n\u001b[0;32m     49\u001b[0m     patience\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     50\u001b[0m     validation_interval\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     51\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     52\u001b[0m     pca_cols\u001b[38;5;241m=\u001b[39mpca_cols,\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:317\u001b[0m, in \u001b[0;36mtrain_func\u001b[1;34m(train_loader, val_data, model, optimizer, scheduler, criterion, epochs, device, wbLogger, wbTagger, wbScatter, directory_path, project_name, experiment_name, popularities, patience, validation_interval, max_grad_norm, pca_cols)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, now())\n\u001b[1;32m--> 317\u001b[0m     model, loss_histories, node_stats, mhandler, shandler \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[0;32m    318\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    319\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    320\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m    321\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    322\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m    323\u001b[0m         max_grad_norm\u001b[38;5;241m=\u001b[39mmax_grad_norm,\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;66;03m# freq_tensor=popularities  # For Negative Sampling\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] Node Statics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mprint\u001b[39m(node_stats)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:167\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, device, optimizer, train_loader, criterion, max_grad_norm)\u001b[0m\n\u001b[0;32m    164\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    165\u001b[0m batch_data \u001b[38;5;241m=\u001b[39m batch_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 167\u001b[0m out, loss_entories \u001b[38;5;241m=\u001b[39m model(batch_data)\n\u001b[0;32m    169\u001b[0m main_loss_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loss_entories) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\model.py:518\u001b[0m, in \u001b[0;36mRecommendationModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# data.set_value_dict(\"x\", self.layer_norm.initial_forward(data.x_dict))\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_abration_wo_cl:\n\u001b[1;32m--> 518\u001b[0m     intention_x, _, cl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintention_cl(data)\n\u001b[0;32m    519\u001b[0m     data\u001b[38;5;241m.\u001b[39mset_value_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\n\u001b[0;32m    520\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m: intention_x\n\u001b[0;32m    521\u001b[0m     })\n\u001b[0;32m    522\u001b[0m     data\u001b[38;5;241m.\u001b[39mset_value_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintention_cl_after(data\u001b[38;5;241m.\u001b[39mx_dict))\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\model.py:113\u001b[0m, in \u001b[0;36mNutrientCaptionContrastiveLearning.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(nutrient_emb\u001b[38;5;241m.\u001b[39mdevice, caption_emb\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(nutrient_emb\u001b[38;5;241m.\u001b[39mshape, caption_emb\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 113\u001b[0m contrastive_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_contrastive(nutrient_emb, caption_emb)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 2) クラスタロス計算\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\loss.py:58\u001b[0m, in \u001b[0;36mContrastiveLoss.forward\u001b[1;34m(self, z_A, z_B)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(similarity_matrix\u001b[38;5;241m.\u001b[39mdevice, labels\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(similarity_matrix\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 58\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(similarity_matrix, labels)\n\u001b[0;32m     59\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(losses))\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def wandb_logger(**kwargs):\n",
    "    try:\n",
    "        wandb.log(**kwargs)\n",
    "    except:\n",
    "        print(kwargs)\n",
    "        pass\n",
    "\n",
    "def wandb_tagger(*args):\n",
    "    try:\n",
    "        wandb.run.tags = list(wandb.run.tags) + list(args)\n",
    "    except:\n",
    "        print(args)\n",
    "        pass\n",
    "\n",
    "def wandb_scatter(df, step, title):\n",
    "    df[\"step\"] = step\n",
    "    table = wandb.Table(data=df, columns=[\"PC1\", \"PC2\", \"node_type\"])\n",
    "    color_cahrt = wandb.plot.scatter(\n",
    "        table,\n",
    "        \"PC1\",\n",
    "        \"PC2\",\n",
    "        title=title,\n",
    "    )\n",
    "    wandb.run.log({f\"scatter_step_{step}\": color_cahrt},\n",
    "                step=step)\n",
    "\n",
    "\n",
    "pca_cols = [\"intention\", \"taste\", \"image\"]\n",
    "\n",
    "criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "\n",
    "\n",
    "train_func(\n",
    "    train_loader,\n",
    "    val_data,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=CONFIG[\"epochs\"],\n",
    "    device=device,\n",
    "    wbLogger=wandb_logger,\n",
    "    wbTagger=wandb_tagger,\n",
    "    wbScatter=wandb_scatter,\n",
    "    directory_path=PATH,\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=run_name,\n",
    "    popularities=pops,\n",
    "    patience=CONFIG[\"patience\"],\n",
    "    validation_interval=CONFIG[\"validation_interval\"],\n",
    "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
    "    pca_cols=pca_cols,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_statics, t_mhandler = evaluate_model(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    device=CONFIG[\"device\"],\n",
    "    freq_tensor=pops,\n",
    "    desc=\"[Test]\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Score Statics: \")\n",
    "print(score_statics.log(prefix=\"test-score-statics\", num_round=4))\n",
    "wandb_logger(data=score_statics.log(prefix=\"test-score-statics\"))\n",
    "\n",
    "print(\"handler Result: \")\n",
    "print(t_mhandler.log(prefix=\"test-handler\", num_round=4))\n",
    "wandb_logger(data=t_mhandler.log(prefix=\"test-handler\", num_round=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config[\"criterion\"] = str(criterion.__class__.__name__)\n",
    "wandb.run.tags = list(wandb.run.tags) + [\"image_fine_tuned\"]\n",
    "\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"crashed\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"all_same_result\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"manual_stopped\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"over_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_satisfied\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"is_trial_model\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNMF-CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
