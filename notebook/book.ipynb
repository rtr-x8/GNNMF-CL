{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "## In Google Coalbo\n",
    "1. Download this notebook\n",
    "2. Uploda to Google Coalbo\n",
    "3. Excute\n",
    "\n",
    "\n",
    "## In Local\n",
    "\n",
    "NOTICE: Required CUDA 12.2, Run on Windows 11 64bit\n",
    "1. Clone Repository\n",
    "```bash\n",
    "git clone git@github.com:rtr-x8/GNNMF-CL.git\n",
    "```\n",
    "2. Create conda environment by Anaconda Prompt\n",
    "```bash\n",
    "conda create -n GNNMF-CL python=3.11.11 -y\n",
    "conda activate GNNMF-CL\n",
    "conda install -c anaconda ipykernel -y\n",
    "python -m ipykernel install --user --name GNNMF-CL --display-name \"GNNMF-CL Env\"\n",
    "\n",
    "```\n",
    "3. Select Conda Environment in your Edirot(ex. VSCODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "# expect Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Once\n",
    "\"\"\"\n",
    "!pip uninstall torch -y\n",
    "!pip install -q --no-cache-dir torch==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse pyg-lib torch-geometric torchvision -y\n",
    "!pip install -q --no-cache-dir torch-geometric\n",
    "!pip install -q --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q --no-cache-dir torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q --no-cache-dir install torchmetrics\n",
    "\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install scikit-learn tqdm pandas numpy setuptools datetime pytz sentence-transformers matplotlib seaborn\n",
    "!pip install -q python-dotenv wandb\n",
    "!pip install torchinfo\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyg_lib\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if \"vingat\" in sys.modules:\n",
    "    del sys.modules[\"vingat\"]\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vingat.logger import get_run_name, log_metrics\n",
    "from vingat.assertion import assert_package_versions\n",
    "from vingat.loader import (\n",
    "    core_file_loader, load_recipe_nutrients, load_ingredients,\n",
    "    load_recipe_ingredients, load_recipe_cooking_directions,\n",
    "    load_ingredients_with_embeddings, load_recipe_image_embeddings, load_recipe_image_embeddings_ft,\n",
    "    load_recipe_image_vlm_caption,\n",
    "    load_recipe_cooking_directions_embeddings,\n",
    "    load_recipe_image_vlm_caption_embeddings,\n",
    "    load_user_embeddings, load_alternative_ingredients,\n",
    "    train_dataclustering, calculate_cluster, load_clouster_centers)\n",
    "from vingat.loss import BPRLoss\n",
    "from vingat.model import RecommendationModel\n",
    "from vingat.functions import evaluate_model, save_model, train_func, get_item_popularity\n",
    "from vingat import __version__ as vingat_version\n",
    "from vingat.dataloader import create_base_hetero, mask_hetero, create_dataloader\n",
    "from vingat.visualizer import visualize_node_pca\n",
    "from vingat.preprocess import filter_recipe_ingredient, NutrientStandardPreprocess\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "assert_package_versions() # assert versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandab_api = os.getenv('WANDB_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from vingat.loader import use_nutritions\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "PROJECT_NAME = \"vingat-v3_local\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "CONFIG = {\n",
    "    \"architecture\": \"LightGCN, HGT, GAT\",\n",
    "    \"_mode\" : \"in_local\",\n",
    "    \"batch_size\": 256,\n",
    "    \"bprloss_reg_lambda\": 0.001,\n",
    "    \"cl_loss_rate\": 0.2,\n",
    "    \"cluster_margin\": 0.5,\n",
    "    \"cluster_loss_weight\": 1.2,\n",
    "    \"criterion\": \"\",\n",
    "    \"default_decay\": 0.00002,\n",
    "    \"device\": device,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 20,\n",
    "    \"filter_ingredient_sim_score\": 0.7,\n",
    "    \"fusion_gnn_after_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_resisual_alpha\": 0.5,\n",
    "    \"fusion_layers\": 1,\n",
    "    \"hidden_dimention\": 128,\n",
    "    \"image_encoder_low_rank_dim\": 64,\n",
    "    \"input_cooking_direction_dim\": 384,\n",
    "    \"input_image_dim\": 1024,\n",
    "    \"input_ingredient_dim\": 384,\n",
    "    \"input_vlm_caption_dim\": 384,\n",
    "    \"intention_cl_after_dropout_rate\": 0.2,\n",
    "    \"intention_layers\": 1,\n",
    "    \"item_encoder_dropout_rate\": 0.2,\n",
    "    \"item_encoder_low_rank_dim\": 64,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"link_predictor_dropout_rate\": 0.2,\n",
    "    \"link_predictor_leaky_relu_slope\": 0.3,\n",
    "    \"max_grad_norm\": 30,\n",
    "    \"multi_head\": 1,\n",
    "    \"node_embeding_dimmention\": 32,\n",
    "    \"nutrient_dim\": 20,\n",
    "    \"patience\": 20,  #  Early stop at least, * validation_interval\n",
    "    \"pyg_lib v\": pyg_lib.__version__,\n",
    "    \"rating_threshold\": 3.5,\n",
    "    \"scheduler_gamma\": 0.975,\n",
    "    \"scheduler_size\": 10,\n",
    "    \"seed\": 2020,\n",
    "    \"sencing_layers\": 1,\n",
    "    \"sensing_gnn_resisual_alpha\": 0.5,\n",
    "    \"taste_gnn_after_dropout_rate\": 0.2,\n",
    "    \"taste_gnn_dropout_rate\": 0.2,\n",
    "    \"temperature\": 0.1,\n",
    "    \"torch v\": torch.__version__,\n",
    "    \"torch_geometric v\": torch_geometric.__version__,\n",
    "    \"torch_scatter v\": torch_scatter.__version__,\n",
    "    \"torch_sparse v\": torch_sparse.__version__,\n",
    "    \"user_encoder_dropout_rate\": 0.2,\n",
    "    \"user_encoder_low_rank_dim\": 64,\n",
    "    \"user_encoder_weight_decay\": 0.000001,\n",
    "    \"validation_interval\": 5,\n",
    "    \"vingat_v\": vingat_version,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "\n",
    "run_name = get_run_name()\n",
    "run_name = f\"{run_name}_{vingat_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=wandab_api)\n",
    "wandb.init(\n",
    "  project=PROJECT_NAME,\n",
    "  name=run_name,\n",
    "  config=CONFIG,\n",
    "  tags=[\"in_local\", \"use_mini_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "\n",
    "# File loader\n",
    "core_recipes, core_train_rating, core_test_rating, core_val_rating = core_file_loader(PATH, CONFIG[\"rating_threshold\"])\n",
    "core_recipe_indices = core_recipes.index.values\n",
    "recipe_nutrients = load_recipe_nutrients(PATH, core_recipes.copy())\n",
    "ingredients = load_ingredients(PATH, core_recipes.copy())\n",
    "alternative_ingredients = load_alternative_ingredients(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_ingredients = load_recipe_ingredients(PATH, core_recipes.copy())\n",
    "recipe_cooking_directions = load_recipe_cooking_directions(PATH, core_recipes.copy())\n",
    "ingredients_with_embeddings = load_ingredients_with_embeddings(PATH, ingredients.copy())\n",
    "recipe_image_embeddings = load_recipe_image_embeddings_ft(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_image_vlm_caption = load_recipe_image_vlm_caption(PATH)\n",
    "recipe_cooking_directions_embeddings = load_recipe_cooking_directions_embeddings(PATH, recipe_cooking_directions.copy())\n",
    "recipe_ingredients = filter_recipe_ingredient(recipe_ingredients, alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "ingredients = ingredients[ingredients.index.isin(recipe_ingredients[\"ingredient_id\"])]\n",
    "recipe_image_vlm_caption_embeddings = load_recipe_image_vlm_caption_embeddings(PATH, recipe_image_vlm_caption.copy())\n",
    "\n",
    "train_nutrients, kmeans_model, scaler = train_dataclustering(\n",
    "    train_data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id)][use_nutritions],\n",
    "    n_cluster=6,\n",
    "    path=PATH\n",
    ")\n",
    "test_recipe_ids = set(core_train_rating.recipe_id) - set()\n",
    "test_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_test_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "valid_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_val_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "recipe_nutrients = pd.concat([\n",
    "    train_nutrients, test_nutrients, valid_nutrients\n",
    "])\n",
    "recipe_nutrients = recipe_nutrients.loc[~recipe_nutrients.index.duplicated(keep='first')]\n",
    "recipe_cluster_centers = load_clouster_centers(kmeanth_model=kmeans_model, device=device)\n",
    "\n",
    "train_nutrients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([1, 2, 3, 4, 5]) - set([4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutri_scalar = NutrientStandardPreprocess(use_nutrients=use_nutritions)\n",
    "recipe_nutrients = nutri_scalar.do(\n",
    "  train_recipe_ids=core_train_rating.recipe_id.unique(),\n",
    "  test_recipe_ids=core_test_rating.recipe_id.unique(),\n",
    "  val_recipe_ids=core_val_rating.recipe_id.unique(),\n",
    "  recipe_nutrients=recipe_nutrients\n",
    ")\n",
    "recipe_cluster_centers = nutri_scalar.transform_from_tensor(recipe_cluster_centers)\n",
    "recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id), \"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mini data\n",
    "\"\"\"\n",
    "mini_path = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "mini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\n",
    "user_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\n",
    "recipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\n",
    "mini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\n",
    "mini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\n",
    "mini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "mini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\n",
    "mini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\n",
    "mini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\n",
    "mini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\n",
    "mini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\n",
    "mini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "mini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "\n",
    "diff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\n",
    "mini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\n",
    "\n",
    "mini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\n",
    "mini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\n",
    "mini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\n",
    "mini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\n",
    "mini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\n",
    "mini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\n",
    "mini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\n",
    "mini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\n",
    "mini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\n",
    "mini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\n",
    "mini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\n",
    "mini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\n",
    "mini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\n",
    "mini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating[\"recipe_id\"])].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(nutri_scalar.transform(recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating[\"recipe_id\"])])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(recipe_cluster_centers.cpu().numpy()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop()\n",
    "\n",
    "data, user_lencoder, item_lencoder, ing_lencoder = create_base_hetero(\n",
    "    core_train_rating=core_train_rating,\n",
    "    core_test_rating=core_test_rating,\n",
    "    core_val_rating=core_val_rating,\n",
    "    ingredients=ingredients,\n",
    "    recipe_nutrients=recipe_nutrients,\n",
    "    recipe_image_embeddings=recipe_image_embeddings,\n",
    "    recipe_image_vlm_caption_embeddings=recipe_image_vlm_caption_embeddings,\n",
    "    recipe_cooking_directions_embeddings=recipe_cooking_directions_embeddings,\n",
    "    ingredients_with_embeddings=ingredients_with_embeddings,\n",
    "    directory_path=PATH,\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    ")\n",
    "\n",
    "train_data, ss = mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=True)\n",
    "test_data, _ = mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "val_data, _ = mask_hetero(data, core_val_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "\n",
    "mini_train = test_data.clone()\n",
    "pops = get_item_popularity(device, item_lencoder, PATH, CONFIG[\"rating_threshold\"])\n",
    "\n",
    "train_loader = create_dataloader(train_data, CONFIG[\"batch_size\"], num_workers=2, neg_sampling_ratio=1.0, popularity=pops, is_abration_cl=False)\n",
    "test_loader = create_dataloader(test_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n",
    "val_loader = create_dataloader(val_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nデータ構造\")\n",
    "train_data[\"intention\"][\"cluster\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = RecommendationModel(\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    node_embeding_dimmention=CONFIG[\"node_embeding_dimmention\"],\n",
    "    num_user=len(user_lencoder.classes_),\n",
    "    num_item=len(item_lencoder.classes_),\n",
    "    nutrient_dim=CONFIG[\"nutrient_dim\"],\n",
    "    num_heads=CONFIG[\"multi_head\"],\n",
    "    sencing_layers=CONFIG[\"sencing_layers\"],\n",
    "    fusion_layers=CONFIG[\"fusion_layers\"],\n",
    "    intention_layers=CONFIG[\"intention_layers\"],\n",
    "    temperature=CONFIG[\"temperature\"],\n",
    "    cl_loss_rate=CONFIG[\"cl_loss_rate\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    "    user_encoder_low_rank_dim=CONFIG[\"user_encoder_low_rank_dim\"],\n",
    "    item_encoder_low_rank_dim=CONFIG[\"item_encoder_low_rank_dim\"],\n",
    "    user_encoder_dropout_rate=CONFIG[\"user_encoder_dropout_rate\"],\n",
    "    item_encoder_dropout_rate=CONFIG[\"item_encoder_dropout_rate\"],\n",
    "    intention_cl_after_dropout_rate=CONFIG[\"intention_cl_after_dropout_rate\"],\n",
    "    taste_gnn_dropout_rate=CONFIG[\"taste_gnn_dropout_rate\"],\n",
    "    taste_gnn_after_dropout_rate=CONFIG[\"taste_gnn_after_dropout_rate\"],\n",
    "    fusion_gnn_dropout_rate=CONFIG[\"fusion_gnn_dropout_rate\"],\n",
    "    fusion_gnn_after_dropout_rate=CONFIG[\"fusion_gnn_after_dropout_rate\"],\n",
    "    link_predictor_dropout_rate=CONFIG[\"link_predictor_dropout_rate\"],\n",
    "    link_predictor_leaky_relu_slope=CONFIG[\"link_predictor_leaky_relu_slope\"],\n",
    "    sensing_gnn_resisual_alpha=CONFIG[\"sensing_gnn_resisual_alpha\"],\n",
    "    fusion_gnn_resisual_alpha=CONFIG[\"fusion_gnn_resisual_alpha\"],\n",
    "    is_abration_wo_cl=False,\n",
    "    is_abration_wo_taste=False,\n",
    "    image_encoder_low_rank_dim=CONFIG[\"image_encoder_low_rank_dim\"],\n",
    "    cluster_centers=recipe_cluster_centers,\n",
    "    cluster_margin=CONFIG[\"cluster_margin\"],\n",
    "    cluster_loss_weight=CONFIG[\"cluster_loss_weight\"],\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "user_encoder_params = list(model.user_encoder.parameters())\n",
    "\n",
    "other_params = [\n",
    "    p for p in model.parameters()\n",
    "    if not any(torch.equal(p.data, up.data) for up in user_encoder_params)\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": user_encoder_params,\n",
    "            \"weight_decay\": CONFIG[\"user_encoder_weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": other_params,\n",
    "            \"weight_decay\": CONFIG[\"default_decay\"],\n",
    "        }\n",
    "    ],\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    # weight_decay=CONFIG[\"default_decay\"],\n",
    ")\n",
    "\n",
    "# criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=CONFIG[\"scheduler_size\"],\n",
    "    gamma=CONFIG[\"scheduler_gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model_summary = summary(model, verbose=0)\n",
    "\n",
    "summary_text = str(model_summary)\n",
    "summary_text = summary_text.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "wandb.log({\"model_summary\": wandb.Html(summary_text)})\n",
    "print(\"\\n\\n\\nモデルの構造\")\n",
    "print(model_summary)\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m pca_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaste\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m BPRLoss(reg_lambda\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbprloss_reg_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m train_func(\n\u001b[0;32m     34\u001b[0m     train_loader,\n\u001b[0;32m     35\u001b[0m     val_data,\n\u001b[0;32m     36\u001b[0m     model,\n\u001b[0;32m     37\u001b[0m     optimizer,\n\u001b[0;32m     38\u001b[0m     scheduler,\n\u001b[0;32m     39\u001b[0m     criterion,\n\u001b[0;32m     40\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     42\u001b[0m     wbLogger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[0;32m     43\u001b[0m     wbTagger\u001b[38;5;241m=\u001b[39mwandb_tagger,\n\u001b[0;32m     44\u001b[0m     wbScatter\u001b[38;5;241m=\u001b[39mwandb_scatter,\n\u001b[0;32m     45\u001b[0m     directory_path\u001b[38;5;241m=\u001b[39mPATH,\n\u001b[0;32m     46\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mPROJECT_NAME,\n\u001b[0;32m     47\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m     48\u001b[0m     popularities\u001b[38;5;241m=\u001b[39mpops,\n\u001b[0;32m     49\u001b[0m     patience\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     50\u001b[0m     validation_interval\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     51\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     52\u001b[0m     pca_cols\u001b[38;5;241m=\u001b[39mpca_cols,\n\u001b[0;32m     53\u001b[0m     recommendation_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:381\u001b[0m, in \u001b[0;36mtrain_func\u001b[1;34m(train_loader, val_data, model, optimizer, scheduler, criterion, epochs, device, wbLogger, wbTagger, wbScatter, directory_path, project_name, experiment_name, popularities, recommendation_loss_weight, patience, validation_interval, max_grad_norm, pca_cols)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, now())\n\u001b[1;32m--> 381\u001b[0m     model, loss_histories, node_stats, mhandler, shandler \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[0;32m    382\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    383\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    384\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m    385\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    386\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m    387\u001b[0m         max_grad_norm\u001b[38;5;241m=\u001b[39mmax_grad_norm,\n\u001b[0;32m    388\u001b[0m         recommendation_loss_weight\u001b[38;5;241m=\u001b[39mrecommendation_loss_weight\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;66;03m# freq_tensor=popularities  # For Negative Sampling\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] Node Statics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mprint\u001b[39m(node_stats)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:207\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, device, optimizer, train_loader, criterion, max_grad_norm, recommendation_loss_weight)\u001b[0m\n\u001b[0;32m    205\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    206\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    208\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    209\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch_geometric\\loader\\base.py:39\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_fn(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator))\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(wait([\u001b[38;5;28mself\u001b[39m], timeout))\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\multiprocessing\\connection.py:896\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    893\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    894\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 896\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[38;5;241m.\u001b[39mkeys(), timeout)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\multiprocessing\\connection.py:828\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    826\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 828\u001b[0m     res \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def wandb_logger(**kwargs):\n",
    "    try:\n",
    "        wandb.log(**kwargs)\n",
    "    except:\n",
    "        print(kwargs)\n",
    "        pass\n",
    "\n",
    "def wandb_tagger(*args):\n",
    "    try:\n",
    "        wandb.run.tags = list(wandb.run.tags) + list(args)\n",
    "    except:\n",
    "        print(args)\n",
    "        pass\n",
    "\n",
    "def wandb_scatter(df, step, title):\n",
    "    df[\"step\"] = step\n",
    "    table = wandb.Table(data=df, columns=[\"PC1\", \"PC2\", \"node_type\"])\n",
    "    color_cahrt = wandb.plot.scatter(\n",
    "        table,\n",
    "        \"PC1\",\n",
    "        \"PC2\",\n",
    "        title=title,\n",
    "    )\n",
    "    wandb.run.log({f\"scatter_step_{step}\": color_cahrt},\n",
    "                step=step)\n",
    "\n",
    "\n",
    "pca_cols = [\"intention\", \"taste\", \"image\"]\n",
    "\n",
    "criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "\n",
    "\n",
    "train_func(\n",
    "    train_loader,\n",
    "    val_data,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=CONFIG[\"epochs\"],\n",
    "    device=device,\n",
    "    wbLogger=wandb_logger,\n",
    "    wbTagger=wandb_tagger,\n",
    "    wbScatter=wandb_scatter,\n",
    "    directory_path=PATH,\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=run_name,\n",
    "    popularities=pops,\n",
    "    patience=CONFIG[\"patience\"],\n",
    "    validation_interval=CONFIG[\"validation_interval\"],\n",
    "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
    "    pca_cols=pca_cols,\n",
    "    recommendation_loss_weight=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_statics, t_mhandler = evaluate_model(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    device=CONFIG[\"device\"],\n",
    "    freq_tensor=pops,\n",
    "    desc=\"[Test]\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Score Statics: \")\n",
    "print(score_statics.log(prefix=\"test-score-statics\", num_round=4))\n",
    "wandb_logger(data=score_statics.log(prefix=\"test-score-statics\"))\n",
    "\n",
    "print(\"handler Result: \")\n",
    "print(t_mhandler.log(prefix=\"test-handler\", num_round=4))\n",
    "wandb_logger(data=t_mhandler.log(prefix=\"test-handler\", num_round=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config[\"criterion\"] = str(criterion.__class__.__name__)\n",
    "wandb.run.tags = list(wandb.run.tags) + [\"image_fine_tuned\"]\n",
    "\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"crashed\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"all_same_result\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"manual_stopped\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"over_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_satisfied\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"is_trial_model\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNMF-CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
