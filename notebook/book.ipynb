{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "## In Google Coalbo\n",
    "1. Download this notebook\n",
    "2. Uploda to Google Coalbo\n",
    "3. Excute\n",
    "\n",
    "\n",
    "## In Local\n",
    "\n",
    "NOTICE: Required CUDA 12.2, Run on Windows 11 64bit\n",
    "1. Clone Repository\n",
    "```bash\n",
    "git clone git@github.com:rtr-x8/GNNMF-CL.git\n",
    "```\n",
    "2. Create conda environment by Anaconda Prompt\n",
    "```bash\n",
    "conda create -n GNNMF-CL python=3.11.11 -y\n",
    "conda activate GNNMF-CL\n",
    "conda install -c anaconda ipykernel -y\n",
    "python -m ipykernel install --user --name GNNMF-CL --display-name \"GNNMF-CL Env\"\n",
    "\n",
    "```\n",
    "3. Select Conda Environment in your Edirot(ex. VSCODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "# expect Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Once\n",
    "\"\"\"\n",
    "!pip uninstall torch -y\n",
    "!pip install -q --no-cache-dir torch==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse pyg-lib torch-geometric torchvision -y\n",
    "!pip install -q --no-cache-dir torch-geometric\n",
    "!pip install -q --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q --no-cache-dir torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q --no-cache-dir install torchmetrics\n",
    "\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install scikit-learn tqdm pandas numpy setuptools datetime pytz sentence-transformers matplotlib seaborn\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyg_lib\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if \"vingat\" in sys.modules:\n",
    "    del sys.modules[\"vingat\"]\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vingat.logger import get_run_name, log_metrics\n",
    "from vingat.assertion import assert_package_versions\n",
    "from vingat.loader import (\n",
    "    core_file_loader, load_recipe_nutrients, load_ingredients,\n",
    "    load_recipe_ingredients, load_recipe_cooking_directions,\n",
    "    load_ingredients_with_embeddings, load_recipe_image_embeddings, load_recipe_image_embeddings_ft,\n",
    "    load_recipe_image_vlm_caption,\n",
    "    load_recipe_cooking_directions_embeddings,\n",
    "    load_recipe_image_vlm_caption_embeddings,\n",
    "    load_user_embeddings, load_alternative_ingredients,\n",
    "    train_dataclustering, calculate_cluster, load_clouster_centers)\n",
    "from vingat.loss import BPRLoss\n",
    "from vingat.model import RecommendationModel\n",
    "from vingat.functions import evaluate_model, save_model, train_func, get_item_popularity\n",
    "from vingat import __version__ as vingat_version\n",
    "from vingat.dataloader import create_base_hetero, mask_hetero, create_dataloader\n",
    "from vingat.visualizer import visualize_node_pca\n",
    "from vingat.preprocess import filter_recipe_ingredient\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "assert_package_versions() # assert versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv wandb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandab_api = os.getenv('WANDB_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from vingat.loader import use_nutritions\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "PROJECT_NAME = \"vingat-v3_local\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "CONFIG = {\n",
    "    \"architecture\": \"LightGCN, HGT, GAT\",\n",
    "    \"_mode\" : \"in_local\",\n",
    "    \"batch_size\": 256,\n",
    "    \"bprloss_reg_lambda\": 0.001,\n",
    "    \"cl_loss_rate\": 0.2,\n",
    "    \"cluster_margin\": 30,\n",
    "    \"cluster_loss_weight\": 1.2,\n",
    "    \"criterion\": \"\",\n",
    "    \"default_decay\": 0.00002,\n",
    "    \"device\": device,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 20,\n",
    "    \"filter_ingredient_sim_score\": 0.7,\n",
    "    \"fusion_gnn_after_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_resisual_alpha\": 0.5,\n",
    "    \"fusion_layers\": 1,\n",
    "    \"hidden_dimention\": 128,\n",
    "    \"image_encoder_low_rank_dim\": 64,\n",
    "    \"input_cooking_direction_dim\": 384,\n",
    "    \"input_image_dim\": 1024,\n",
    "    \"input_ingredient_dim\": 384,\n",
    "    \"input_vlm_caption_dim\": 384,\n",
    "    \"intention_cl_after_dropout_rate\": 0.2,\n",
    "    \"intention_layers\": 1,\n",
    "    \"item_encoder_dropout_rate\": 0.2,\n",
    "    \"item_encoder_low_rank_dim\": 64,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"link_predictor_dropout_rate\": 0.2,\n",
    "    \"link_predictor_leaky_relu_slope\": 0.3,\n",
    "    \"max_grad_norm\": 30,\n",
    "    \"multi_head\": 1,\n",
    "    \"node_embeding_dimmention\": 32,\n",
    "    \"nutrient_dim\": 20,\n",
    "    \"patience\": 20,  #  Early stop at least, * validation_interval\n",
    "    \"pyg_lib v\": pyg_lib.__version__,\n",
    "    \"rating_threshold\": 3.5,\n",
    "    \"scheduler_gamma\": 0.975,\n",
    "    \"scheduler_size\": 10,\n",
    "    \"seed\": 2020,\n",
    "    \"sencing_layers\": 1,\n",
    "    \"sensing_gnn_resisual_alpha\": 0.5,\n",
    "    \"taste_gnn_after_dropout_rate\": 0.2,\n",
    "    \"taste_gnn_dropout_rate\": 0.2,\n",
    "    \"temperature\": 0.1,\n",
    "    \"torch v\": torch.__version__,\n",
    "    \"torch_geometric v\": torch_geometric.__version__,\n",
    "    \"torch_scatter v\": torch_scatter.__version__,\n",
    "    \"torch_sparse v\": torch_sparse.__version__,\n",
    "    \"user_encoder_dropout_rate\": 0.2,\n",
    "    \"user_encoder_low_rank_dim\": 64,\n",
    "    \"user_encoder_weight_decay\": 0.000001,\n",
    "    \"validation_interval\": 5,\n",
    "    \"vingat_v\": vingat_version,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "\n",
    "run_name = get_run_name()\n",
    "run_name = f\"{run_name}_{vingat_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\matsuoka\\_netrc\n",
      "wandb: Currently logged in as: ryu-2-24 (ryu-2-24-shiga-u-ac-jp) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.8s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\wandb\\run-20250320_004154-x3ry73yf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/x3ry73yf' target=\"_blank\">run-20250320-004151_0.3.28</a></strong> to <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/x3ry73yf' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/x3ry73yf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/x3ry73yf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2b3cefe8250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandab_api)\n",
    "wandb.init(\n",
    "  project=PROJECT_NAME,\n",
    "  name=run_name,\n",
    "  config=CONFIG,\n",
    "  tags=[\"in_local\", \"use_mini_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n",
      "recipe_nutrients is loaded\n",
      "ingredients is loaded\n",
      "recipe_ingredients is loaded\n",
      "recipe_cooking_directions is loaded\n",
      "ingredients_with_embeddings is loaded\n",
      "recipe_image_embeddings_ft is loaded\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "\n",
    "# File loader\n",
    "core_recipes, core_train_rating, core_test_rating, core_val_rating = core_file_loader(PATH, CONFIG[\"rating_threshold\"])\n",
    "core_recipe_indices = core_recipes.index.values\n",
    "recipe_nutrients = load_recipe_nutrients(PATH, core_recipes.copy())\n",
    "ingredients = load_ingredients(PATH, core_recipes.copy())\n",
    "alternative_ingredients = load_alternative_ingredients(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_ingredients = load_recipe_ingredients(PATH, core_recipes.copy())\n",
    "recipe_cooking_directions = load_recipe_cooking_directions(PATH, core_recipes.copy())\n",
    "ingredients_with_embeddings = load_ingredients_with_embeddings(PATH, ingredients.copy())\n",
    "recipe_image_embeddings = load_recipe_image_embeddings_ft(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_image_vlm_caption = load_recipe_image_vlm_caption(PATH)\n",
    "recipe_cooking_directions_embeddings = load_recipe_cooking_directions_embeddings(PATH, recipe_cooking_directions.copy())\n",
    "recipe_ingredients = filter_recipe_ingredient(recipe_ingredients, alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "ingredients = ingredients[ingredients.index.isin(recipe_ingredients[\"ingredient_id\"])]\n",
    "recipe_image_vlm_caption_embeddings = load_recipe_image_vlm_caption_embeddings(PATH, recipe_image_vlm_caption.copy())\n",
    "\n",
    "train_nutrients, kmeans_model, scaler = train_dataclustering(\n",
    "    train_data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id)][use_nutritions],\n",
    "    n_cluster=6,\n",
    "    path=PATH\n",
    ")\n",
    "test_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_test_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "valid_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_val_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "recipe_nutrients = pd.concat([\n",
    "    train_nutrients, test_nutrients, valid_nutrients\n",
    "])\n",
    "recipe_nutrients = recipe_nutrients.loc[~recipe_nutrients.index.duplicated(keep='first')]\n",
    "recipe_cluster_centers = load_clouster_centers(kmeanth_model=kmeans_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmini_path = os.path.join(os.getcwd(), \\'..\\', \\'data\\', \\'mini\\')\\nmini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\\nmini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\\nmini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\\nuser_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\\nrecipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\\nmini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\\nmini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\\nmini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\\nmini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\\nmini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\\nmini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\\nmini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\\nmini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\\nmini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\\nmini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\\nmini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\\nmini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\\nmini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\\n\\ndiff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\\nmini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\\n\\nmini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\\nmini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\\nmini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\\nmini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\\nmini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\\nmini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\\nmini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\\nmini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\\nmini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\\nmini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\\nmini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\\nmini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\\nmini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\\nmini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create mini data\n",
    "\"\"\"\n",
    "mini_path = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "mini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\n",
    "user_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\n",
    "recipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\n",
    "mini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\n",
    "mini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\n",
    "mini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "mini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\n",
    "mini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\n",
    "mini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\n",
    "mini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\n",
    "mini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\n",
    "mini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "mini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "\n",
    "diff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\n",
    "mini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\n",
    "\n",
    "mini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\n",
    "mini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\n",
    "mini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\n",
    "mini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\n",
    "mini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\n",
    "mini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\n",
    "mini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\n",
    "mini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\n",
    "mini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\n",
    "mini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\n",
    "mini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\n",
    "mini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\n",
    "mini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\n",
    "mini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n"
     ]
    }
   ],
   "source": [
    "data, user_lencoder, item_lencoder, ing_lencoder = create_base_hetero(\n",
    "    core_train_rating=core_train_rating,\n",
    "    core_test_rating=core_test_rating,\n",
    "    core_val_rating=core_val_rating,\n",
    "    ingredients=ingredients,\n",
    "    recipe_nutrients=recipe_nutrients,\n",
    "    recipe_image_embeddings=recipe_image_embeddings,\n",
    "    recipe_image_vlm_caption_embeddings=recipe_image_vlm_caption_embeddings,\n",
    "    recipe_cooking_directions_embeddings=recipe_cooking_directions_embeddings,\n",
    "    ingredients_with_embeddings=ingredients_with_embeddings,\n",
    "    directory_path=PATH,\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    ")\n",
    "\n",
    "train_data, ss = mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=True)\n",
    "test_data, _ = mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "val_data, _ = mask_hetero(data, core_val_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "\n",
    "mini_train = test_data.clone()\n",
    "pops = get_item_popularity(device, item_lencoder, PATH, CONFIG[\"rating_threshold\"])\n",
    "\n",
    "train_loader = create_dataloader(train_data, CONFIG[\"batch_size\"], num_workers=2, neg_sampling_ratio=1.0, popularity=pops, is_abration_cl=False)\n",
    "test_loader = create_dataloader(test_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n",
    "val_loader = create_dataloader(val_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "データ構造\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    num_nodes=13730,\n",
       "    user_id=[13730],\n",
       "    x=[13730, 128],\n",
       "    id=[13730],\n",
       "  },\n",
       "  item={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    x=[10241, 128],\n",
       "    id=[10241],\n",
       "  },\n",
       "  image={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    org=[10241, 1024],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  intention={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    nutrient=[10241, 20],\n",
       "    cluster=[10241],\n",
       "    caption=[10241, 384],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  taste={\n",
       "    num_nodes=10241,\n",
       "    item_id=[10241],\n",
       "    org=[10241, 384],\n",
       "    x=[10241, 128],\n",
       "  },\n",
       "  ingredient={\n",
       "    num_nodes=7765,\n",
       "    ingredient_id=[7765],\n",
       "    org=[7765, 384],\n",
       "    x=[7765, 128],\n",
       "  },\n",
       "  (image, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_image, image)={ edge_index=[2, 10241] },\n",
       "  (intention, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_intention, intention)={ edge_index=[2, 10241] },\n",
       "  (taste, associated_with, item)={ edge_index=[2, 10241] },\n",
       "  (item, has_taste, taste)={ edge_index=[2, 10241] },\n",
       "  (user, buys, item)={\n",
       "    edge_index=[2, 13539],\n",
       "    edge_label=[13539],\n",
       "    edge_label_index=[2, 13539],\n",
       "  },\n",
       "  (item, bought_by, user)={ edge_index=[2, 13539] },\n",
       "  (ingredient, part_of, taste)={ edge_index=[2, 60709] }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\n\\nデータ構造\")\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = RecommendationModel(\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    node_embeding_dimmention=CONFIG[\"node_embeding_dimmention\"],\n",
    "    num_user=len(user_lencoder.classes_),\n",
    "    num_item=len(item_lencoder.classes_),\n",
    "    nutrient_dim=CONFIG[\"nutrient_dim\"],\n",
    "    num_heads=CONFIG[\"multi_head\"],\n",
    "    sencing_layers=CONFIG[\"sencing_layers\"],\n",
    "    fusion_layers=CONFIG[\"fusion_layers\"],\n",
    "    intention_layers=CONFIG[\"intention_layers\"],\n",
    "    temperature=CONFIG[\"temperature\"],\n",
    "    cl_loss_rate=CONFIG[\"cl_loss_rate\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    "    user_encoder_low_rank_dim=CONFIG[\"user_encoder_low_rank_dim\"],\n",
    "    item_encoder_low_rank_dim=CONFIG[\"item_encoder_low_rank_dim\"],\n",
    "    user_encoder_dropout_rate=CONFIG[\"user_encoder_dropout_rate\"],\n",
    "    item_encoder_dropout_rate=CONFIG[\"item_encoder_dropout_rate\"],\n",
    "    intention_cl_after_dropout_rate=CONFIG[\"intention_cl_after_dropout_rate\"],\n",
    "    taste_gnn_dropout_rate=CONFIG[\"taste_gnn_dropout_rate\"],\n",
    "    taste_gnn_after_dropout_rate=CONFIG[\"taste_gnn_after_dropout_rate\"],\n",
    "    fusion_gnn_dropout_rate=CONFIG[\"fusion_gnn_dropout_rate\"],\n",
    "    fusion_gnn_after_dropout_rate=CONFIG[\"fusion_gnn_after_dropout_rate\"],\n",
    "    link_predictor_dropout_rate=CONFIG[\"link_predictor_dropout_rate\"],\n",
    "    link_predictor_leaky_relu_slope=CONFIG[\"link_predictor_leaky_relu_slope\"],\n",
    "    sensing_gnn_resisual_alpha=CONFIG[\"sensing_gnn_resisual_alpha\"],\n",
    "    fusion_gnn_resisual_alpha=CONFIG[\"fusion_gnn_resisual_alpha\"],\n",
    "    is_abration_wo_cl=False,\n",
    "    is_abration_wo_taste=False,\n",
    "    image_encoder_low_rank_dim=CONFIG[\"image_encoder_low_rank_dim\"],\n",
    "    cluster_centers=recipe_cluster_centers,\n",
    "    cluster_margin=CONFIG[\"cluster_margin\"],\n",
    "    cluster_loss_weight=CONFIG[\"cluster_loss_weight\"],\n",
    ")\n",
    "\n",
    "user_encoder_params = list(model.user_encoder.parameters())\n",
    "other_params = [\n",
    "    p for p in model.parameters()\n",
    "    if not any(torch.equal(p.data, up.data) for up in user_encoder_params)\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": user_encoder_params,\n",
    "            \"weight_decay\": CONFIG[\"user_encoder_weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": other_params,\n",
    "            \"weight_decay\": CONFIG[\"default_decay\"],\n",
    "        }\n",
    "    ],\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    # weight_decay=CONFIG[\"default_decay\"],\n",
    ")\n",
    "\n",
    "# criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=CONFIG[\"scheduler_size\"],\n",
    "    gamma=CONFIG[\"scheduler_gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\matsuoka\\.conda\\envs\\gnnmf-cl\\lib\\site-packages (1.8.0)\n",
      "\n",
      "\n",
      "\n",
      "モデルの構造\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "RecommendationModel                           --\n",
      "├─Sequential: 1-1                             --\n",
      "│    └─Embedding: 2-1                         878,720\n",
      "│    └─Linear: 2-2                            8,320\n",
      "│    └─Dropout: 2-3                           --\n",
      "├─Sequential: 1-2                             --\n",
      "│    └─Embedding: 2-4                         655,424\n",
      "│    └─Linear: 2-5                            8,320\n",
      "│    └─Dropout: 2-6                           --\n",
      "├─LowRankLinear: 1-3                          --\n",
      "│    └─Linear: 2-7                            65,536\n",
      "│    └─Linear: 2-8                            8,320\n",
      "├─Linear: 1-4                                 49,280\n",
      "├─Linear: 1-5                                 49,280\n",
      "├─NutrientCaptionContrastiveLearning: 1-6     --\n",
      "│    └─Sequential: 2-9                        --\n",
      "│    │    └─Linear: 3-1                       1,344\n",
      "│    │    └─ReLU: 3-2                         --\n",
      "│    │    └─Linear: 3-3                       8,320\n",
      "│    └─Sequential: 2-10                       --\n",
      "│    │    └─Linear: 3-4                       98,560\n",
      "│    │    └─ReLU: 3-5                         --\n",
      "│    │    └─Linear: 3-6                       32,896\n",
      "│    └─ContrastiveLoss: 2-11                  --\n",
      "├─Sequential: 1-7                             --\n",
      "│    └─DictActivate: 2-12                     --\n",
      "│    └─DictDropout: 2-13                      --\n",
      "├─ModuleList: 1-8                             --\n",
      "│    └─TasteGNN: 2-14                         --\n",
      "│    │    └─HANConv: 3-7                      49,920\n",
      "├─Sequential: 1-9                             --\n",
      "│    └─DictActivate: 2-15                     --\n",
      "│    └─DictDropout: 2-16                      --\n",
      "├─ModuleList: 1-10                            --\n",
      "│    └─MultiModalFusionGAT: 2-17              --\n",
      "│    │    └─HGTConv: 3-8                      494,090\n",
      "├─Sequential: 1-11                            --\n",
      "│    └─DictActivate: 2-18                     --\n",
      "│    └─DictDropout: 2-19                      --\n",
      "├─Sequential: 1-12                            --\n",
      "│    └─Linear: 2-20                           32,896\n",
      "│    └─LeakyReLU: 2-21                        --\n",
      "│    └─Dropout: 2-22                          --\n",
      "│    └─Linear: 2-23                           129\n",
      "├─DictLayerNormForLayer: 1-13                 --\n",
      "│    └─ModuleDict: 2-24                       --\n",
      "│    │    └─LayerNorm: 3-9                    256\n",
      "│    │    └─LayerNorm: 3-10                   256\n",
      "│    │    └─LayerNorm: 3-11                   256\n",
      "│    │    └─LayerNorm: 3-12                   256\n",
      "│    │    └─LayerNorm: 3-13                   256\n",
      "│    │    └─LayerNorm: 3-14                   256\n",
      "│    └─ModuleDict: 2-25                       --\n",
      "│    │    └─Sequential: 3-15                  33,280\n",
      "│    │    └─Sequential: 3-16                  33,280\n",
      "│    │    └─Sequential: 3-17                  33,280\n",
      "│    │    └─Sequential: 3-18                  33,280\n",
      "│    │    └─Sequential: 3-19                  33,280\n",
      "│    │    └─Sequential: 3-20                  33,280\n",
      "======================================================================\n",
      "Total params: 2,642,571\n",
      "Trainable params: 2,642,571\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "model_summary = summary(model, verbose=0)\n",
    "\n",
    "summary_text = str(model_summary)\n",
    "summary_text = summary_text.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "wandb.log({\"model_summary\": wandb.Html(summary_text)})\n",
    "print(\"\\n\\n\\nモデルの構造\")\n",
    "print(model_summary)\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 2025-03-20 00:42:26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601690e04e014be3a3d052103d44091b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cent_emb.device cuda:0\n",
      "dist_matrix.device cuda:0\n",
      "dist_matrix.shape torch.Size([6, 6])\n",
      "cent_emb.device cuda:0\n",
      "dist_matrix.device cuda:0\n",
      "dist_matrix.shape torch.Size([6, 6])\n",
      "cent_emb.device cuda:0\n",
      "dist_matrix.device cuda:0\n",
      "dist_matrix.shape torch.Size([6, 6])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m pca_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaste\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m BPRLoss(reg_lambda\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbprloss_reg_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m train_func(\n\u001b[0;32m     34\u001b[0m     train_loader,\n\u001b[0;32m     35\u001b[0m     val_data,\n\u001b[0;32m     36\u001b[0m     model,\n\u001b[0;32m     37\u001b[0m     optimizer,\n\u001b[0;32m     38\u001b[0m     scheduler,\n\u001b[0;32m     39\u001b[0m     criterion,\n\u001b[0;32m     40\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     42\u001b[0m     wbLogger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[0;32m     43\u001b[0m     wbTagger\u001b[38;5;241m=\u001b[39mwandb_tagger,\n\u001b[0;32m     44\u001b[0m     wbScatter\u001b[38;5;241m=\u001b[39mwandb_scatter,\n\u001b[0;32m     45\u001b[0m     directory_path\u001b[38;5;241m=\u001b[39mPATH,\n\u001b[0;32m     46\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mPROJECT_NAME,\n\u001b[0;32m     47\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m     48\u001b[0m     popularities\u001b[38;5;241m=\u001b[39mpops,\n\u001b[0;32m     49\u001b[0m     patience\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     50\u001b[0m     validation_interval\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     51\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     52\u001b[0m     pca_cols\u001b[38;5;241m=\u001b[39mpca_cols,\n\u001b[0;32m     53\u001b[0m     recommendation_loss_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     54\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:362\u001b[0m, in \u001b[0;36mtrain_func\u001b[1;34m(train_loader, val_data, model, optimizer, scheduler, criterion, epochs, device, wbLogger, wbTagger, wbScatter, directory_path, project_name, experiment_name, popularities, recommendation_loss_weight, patience, validation_interval, max_grad_norm, pca_cols)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, now())\n\u001b[1;32m--> 362\u001b[0m     model, loss_histories, node_stats, mhandler, shandler \u001b[38;5;241m=\u001b[39m train_one_epoch(\n\u001b[0;32m    363\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    364\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    365\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m    366\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    367\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m    368\u001b[0m         max_grad_norm\u001b[38;5;241m=\u001b[39mmax_grad_norm,\n\u001b[0;32m    369\u001b[0m         recommendation_loss_weight\u001b[38;5;241m=\u001b[39mrecommendation_loss_weight\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;66;03m# freq_tensor=popularities  # For Negative Sampling\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     )\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] Node Statics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mprint\u001b[39m(node_stats)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:255\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, device, optimizer, train_loader, criterion, max_grad_norm, recommendation_loss_weight)\u001b[0m\n\u001b[0;32m    252\u001b[0m loss_entories\u001b[38;5;241m.\u001b[39mappend(main_loss_item)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 255\u001b[0m     xe_loss_result \u001b[38;5;241m=\u001b[39m xe_loss(torch\u001b[38;5;241m.\u001b[39mcat([pos_scores, neg_scores]),\n\u001b[0;32m    256\u001b[0m                              torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[0;32m    257\u001b[0m                                  torch\u001b[38;5;241m.\u001b[39mones_like(pos_scores),\n\u001b[0;32m    258\u001b[0m                                  torch\u001b[38;5;241m.\u001b[39mzeros_like(neg_scores)\n\u001b[0;32m    259\u001b[0m                              ]),\n\u001b[0;32m    260\u001b[0m                              torch\u001b[38;5;241m.\u001b[39mcat([pos_user_ids, neg_user_ids]))\n\u001b[0;32m    261\u001b[0m     loss_entories\u001b[38;5;241m.\u001b[39mappend(LossItem(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxe_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39mxe_loss_result, weight\u001b[38;5;241m=\u001b[39mmain_loss_rate))\n\u001b[0;32m    263\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_item\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m loss_item\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;28;01mfor\u001b[39;00m loss_item \u001b[38;5;129;01min\u001b[39;00m loss_entories)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\loss.py:70\u001b[0m, in \u001b[0;36mXENDCGLoss.forward\u001b[1;34m(self, predictions, targets, indexes)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, predictions, targets, indexes):\n\u001b[1;32m---> 70\u001b[0m     xe_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(predictions, targets)\n\u001b[0;32m     71\u001b[0m     ndcg_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndcg(predictions, targets, indexes\u001b[38;5;241m=\u001b[39mindexes)\n\u001b[0;32m     72\u001b[0m     loss \u001b[38;5;241m=\u001b[39m xe_loss \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ndcg_score)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\functional.py:3172\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3169\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3170\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "def wandb_logger(**kwargs):\n",
    "    try:\n",
    "        wandb.log(**kwargs)\n",
    "    except:\n",
    "        print(kwargs)\n",
    "        pass\n",
    "\n",
    "def wandb_tagger(*args):\n",
    "    try:\n",
    "        wandb.run.tags = list(wandb.run.tags) + list(args)\n",
    "    except:\n",
    "        print(args)\n",
    "        pass\n",
    "\n",
    "def wandb_scatter(df, step, title):\n",
    "    df[\"step\"] = step\n",
    "    table = wandb.Table(data=df, columns=[\"PC1\", \"PC2\", \"node_type\"])\n",
    "    color_cahrt = wandb.plot.scatter(\n",
    "        table,\n",
    "        \"PC1\",\n",
    "        \"PC2\",\n",
    "        title=title,\n",
    "    )\n",
    "    wandb.run.log({f\"scatter_step_{step}\": color_cahrt},\n",
    "                step=step)\n",
    "\n",
    "\n",
    "pca_cols = [\"intention\", \"taste\", \"image\"]\n",
    "\n",
    "criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "\n",
    "\n",
    "train_func(\n",
    "    train_loader,\n",
    "    val_data,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=CONFIG[\"epochs\"],\n",
    "    device=device,\n",
    "    wbLogger=wandb_logger,\n",
    "    wbTagger=wandb_tagger,\n",
    "    wbScatter=wandb_scatter,\n",
    "    directory_path=PATH,\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=run_name,\n",
    "    popularities=pops,\n",
    "    patience=CONFIG[\"patience\"],\n",
    "    validation_interval=CONFIG[\"validation_interval\"],\n",
    "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
    "    pca_cols=pca_cols,\n",
    "    recommendation_loss_weight=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac16a9614ba44126a2fb5c256cd24239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Test]:   0%|          | 0/4483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Statics: \n",
      "{'test-score-statics/pos_mean': 0.5, 'test-score-statics/pos_min': 0.5, 'test-score-statics/pos_max': 0.5, 'test-score-statics/pos_std': 0.0, 'test-score-statics/neg_mean': 0.5, 'test-score-statics/neg_min': 0.5, 'test-score-statics/neg_max': 0.5, 'test-score-statics/neg_std': 0.0, 'test-score-statics/diff_mean': 0.0}\n",
      "handler Result: \n",
      "{'test-handler/AUROC': 0.5, 'test-handler/accuracy': 0.9975, 'test-handler/f1': 0.0, 'test-handler/ndcg@10': 0.0095, 'test-handler/precision@10': 0.1244, 'test-handler/recall': 0.0, 'test-handler/recall@10': 0.9989, 'test-handler/tn': 2241500, 'test-handler/fp': 0, 'test-handler/fn': 5669, 'test-handler/tp': 0}\n"
     ]
    }
   ],
   "source": [
    "score_statics, t_mhandler = evaluate_model(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    device=CONFIG[\"device\"],\n",
    "    freq_tensor=pops,\n",
    "    desc=\"[Test]\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Score Statics: \")\n",
    "print(score_statics.log(prefix=\"test-score-statics\", num_round=4))\n",
    "wandb_logger(data=score_statics.log(prefix=\"test-score-statics\"))\n",
    "\n",
    "print(\"handler Result: \")\n",
    "print(t_mhandler.log(prefix=\"test-handler\", num_round=4))\n",
    "wandb_logger(data=t_mhandler.log(prefix=\"test-handler\", num_round=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test-handler/AUROC</td><td>▁</td></tr><tr><td>test-handler/accuracy</td><td>▁</td></tr><tr><td>test-handler/f1</td><td>▁</td></tr><tr><td>test-handler/fn</td><td>▁</td></tr><tr><td>test-handler/fp</td><td>▁</td></tr><tr><td>test-handler/ndcg@10</td><td>▁</td></tr><tr><td>test-handler/precision@10</td><td>▁</td></tr><tr><td>test-handler/recall</td><td>▁</td></tr><tr><td>test-handler/recall@10</td><td>▁</td></tr><tr><td>test-handler/tn</td><td>▁</td></tr><tr><td>test-handler/tp</td><td>▁</td></tr><tr><td>test-score-statics/diff_mean</td><td>▁</td></tr><tr><td>test-score-statics/neg_max</td><td>▁</td></tr><tr><td>test-score-statics/neg_mean</td><td>▁</td></tr><tr><td>test-score-statics/neg_min</td><td>▁</td></tr><tr><td>test-score-statics/neg_std</td><td>▁</td></tr><tr><td>test-score-statics/pos_max</td><td>▁</td></tr><tr><td>test-score-statics/pos_mean</td><td>▁</td></tr><tr><td>test-score-statics/pos_min</td><td>▁</td></tr><tr><td>test-score-statics/pos_std</td><td>▁</td></tr><tr><td>train-handler/AUROC</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/fn</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/fp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/ndcg@10</td><td>▄▇▃▅█▆▄▄▅▅▅▃▃▂▆▁▄▆█▅</td></tr><tr><td>train-handler/precision@10</td><td>▅▄▄▆▇▆▂▅▄▂▃▃▁▁▃▃▄█▇▄</td></tr><tr><td>train-handler/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/recall@10</td><td>▃▇▂▅▇█▂▁▂▅▃▄▄▃▄▃▄▆▇▆</td></tr><tr><td>train-handler/tn</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-handler/tp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-loss/cl_inter_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-loss/cl_intra_loss</td><td>█▇▆▆▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train-loss/cl_loss</td><td>▄▄▅▇█▄▆▇▁▇▆▇▅██▇▅▆▇▄</td></tr><tr><td>train-loss/main_loss</td><td>██▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train-loss/xe_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/diff_mean</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/neg_max</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/neg_mean</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/neg_min</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/neg_std</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/pos_max</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/pos_mean</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/pos_min</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-score-statics/pos_std</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val-handler/AUROC</td><td>▁▁▁▁</td></tr><tr><td>val-handler/accuracy</td><td>▁▁▁▁</td></tr><tr><td>val-handler/f1</td><td>▁▁▁▁</td></tr><tr><td>val-handler/fn</td><td>▁▁▁▁</td></tr><tr><td>val-handler/fp</td><td>▁▁▁▁</td></tr><tr><td>val-handler/ndcg@10</td><td>▁▁▁▁</td></tr><tr><td>val-handler/precision@10</td><td>▁▁▁▁</td></tr><tr><td>val-handler/recall</td><td>▁▁▁▁</td></tr><tr><td>val-handler/recall@10</td><td>▁▁▁▁</td></tr><tr><td>val-handler/tn</td><td>▁▁▁▁</td></tr><tr><td>val-handler/tp</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/diff_mean</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/neg_max</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/neg_mean</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/neg_min</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/neg_std</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/pos_max</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/pos_mean</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/pos_min</td><td>▁▁▁▁</td></tr><tr><td>val-score-statics/pos_std</td><td>▁▁▁▁</td></tr><tr><td>val/last_lr</td><td>██▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test-handler/AUROC</td><td>0.5</td></tr><tr><td>test-handler/accuracy</td><td>0.99748</td></tr><tr><td>test-handler/f1</td><td>0</td></tr><tr><td>test-handler/fn</td><td>5669</td></tr><tr><td>test-handler/fp</td><td>0</td></tr><tr><td>test-handler/ndcg@10</td><td>0.00952</td></tr><tr><td>test-handler/precision@10</td><td>0.12445</td></tr><tr><td>test-handler/recall</td><td>0</td></tr><tr><td>test-handler/recall@10</td><td>0.99887</td></tr><tr><td>test-handler/tn</td><td>2241500</td></tr><tr><td>test-handler/tp</td><td>0</td></tr><tr><td>test-score-statics/diff_mean</td><td>0</td></tr><tr><td>test-score-statics/neg_max</td><td>0.5</td></tr><tr><td>test-score-statics/neg_mean</td><td>0.5</td></tr><tr><td>test-score-statics/neg_min</td><td>0.5</td></tr><tr><td>test-score-statics/neg_std</td><td>0</td></tr><tr><td>test-score-statics/pos_max</td><td>0.5</td></tr><tr><td>test-score-statics/pos_mean</td><td>0.5</td></tr><tr><td>test-score-statics/pos_min</td><td>0.5</td></tr><tr><td>test-score-statics/pos_std</td><td>0</td></tr><tr><td>train-handler/AUROC</td><td>0.5</td></tr><tr><td>train-handler/accuracy</td><td>0.5</td></tr><tr><td>train-handler/f1</td><td>0</td></tr><tr><td>train-handler/fn</td><td>13539</td></tr><tr><td>train-handler/fp</td><td>0</td></tr><tr><td>train-handler/ndcg@10</td><td>0.49898</td></tr><tr><td>train-handler/precision@10</td><td>0.49771</td></tr><tr><td>train-handler/recall</td><td>0</td></tr><tr><td>train-handler/recall@10</td><td>0.19398</td></tr><tr><td>train-handler/tn</td><td>13539</td></tr><tr><td>train-handler/tp</td><td>0</td></tr><tr><td>train-loss/cl_inter_loss</td><td>14.61507</td></tr><tr><td>train-loss/cl_intra_loss</td><td>0.02779</td></tr><tr><td>train-loss/cl_loss</td><td>7.67626</td></tr><tr><td>train-loss/main_loss</td><td>1.0477</td></tr><tr><td>train-loss/xe_loss</td><td>0</td></tr><tr><td>train-score-statics/diff_mean</td><td>0</td></tr><tr><td>train-score-statics/neg_max</td><td>0.5</td></tr><tr><td>train-score-statics/neg_mean</td><td>0.5</td></tr><tr><td>train-score-statics/neg_min</td><td>0.5</td></tr><tr><td>train-score-statics/neg_std</td><td>0</td></tr><tr><td>train-score-statics/pos_max</td><td>0.5</td></tr><tr><td>train-score-statics/pos_mean</td><td>0.5</td></tr><tr><td>train-score-statics/pos_min</td><td>0.5</td></tr><tr><td>train-score-statics/pos_std</td><td>0</td></tr><tr><td>val-handler/AUROC</td><td>0.5</td></tr><tr><td>val-handler/accuracy</td><td>0.9976</td></tr><tr><td>val-handler/f1</td><td>0</td></tr><tr><td>val-handler/fn</td><td>2669</td></tr><tr><td>val-handler/fp</td><td>0</td></tr><tr><td>val-handler/ndcg@10</td><td>0.0094</td></tr><tr><td>val-handler/precision@10</td><td>0.1212</td></tr><tr><td>val-handler/recall</td><td>0</td></tr><tr><td>val-handler/recall@10</td><td>0.9997</td></tr><tr><td>val-handler/tn</td><td>1096500</td></tr><tr><td>val-handler/tp</td><td>0</td></tr><tr><td>val-score-statics/diff_mean</td><td>-0.0</td></tr><tr><td>val-score-statics/neg_max</td><td>0.5</td></tr><tr><td>val-score-statics/neg_mean</td><td>0.5</td></tr><tr><td>val-score-statics/neg_min</td><td>0.5</td></tr><tr><td>val-score-statics/neg_std</td><td>0</td></tr><tr><td>val-score-statics/pos_max</td><td>0.5</td></tr><tr><td>val-score-statics/pos_mean</td><td>0.5</td></tr><tr><td>val-score-statics/pos_min</td><td>0.5</td></tr><tr><td>val-score-statics/pos_std</td><td>0</td></tr><tr><td>val/last_lr</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-20250319-222233_0.3.28</strong> at: <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/6sy3ewjt' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/6sy3ewjt</a><br> View project at: <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250319_222236-6sy3ewjt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.config[\"criterion\"] = str(criterion.__class__.__name__)\n",
    "wandb.run.tags = list(wandb.run.tags) + [\"image_fine_tuned\"]\n",
    "\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"crashed\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"all_same_result\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"manual_stopped\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"over_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_satisfied\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"is_trial_model\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNMF-CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
