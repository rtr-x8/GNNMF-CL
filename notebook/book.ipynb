{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "## In Google Coalbo\n",
    "1. Download this notebook\n",
    "2. Uploda to Google Coalbo\n",
    "3. Excute\n",
    "\n",
    "\n",
    "## In Local\n",
    "\n",
    "NOTICE: Required CUDA 12.2, Run on Windows 11 64bit\n",
    "1. Clone Repository\n",
    "```bash\n",
    "git clone git@github.com:rtr-x8/GNNMF-CL.git\n",
    "```\n",
    "2. Create conda environment by Anaconda Prompt\n",
    "```bash\n",
    "conda create -n GNNMF-CL python=3.11.11 -y\n",
    "conda activate GNNMF-CL\n",
    "conda install -c anaconda ipykernel -y\n",
    "python -m ipykernel install --user --name GNNMF-CL --display-name \"GNNMF-CL Env\"\n",
    "\n",
    "```\n",
    "3. Select Conda Environment in your Edirot(ex. VSCODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "# expect Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Once\n",
    "\"\"\"\n",
    "!pip uninstall torch -y\n",
    "!pip install -q --no-cache-dir torch==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse pyg-lib torch-geometric torchvision -y\n",
    "!pip install -q --no-cache-dir torch-geometric\n",
    "!pip install -q --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q --no-cache-dir torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q --no-cache-dir install torchmetrics\n",
    "\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "!pip install scikit-learn tqdm pandas numpy setuptools datetime pytz sentence-transformers matplotlib seaborn\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyg_lib\n",
    "import torchvision\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "if \"vingat\" in sys.modules:\n",
    "    del sys.modules[\"vingat\"]\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vingat.logger import get_run_name, log_metrics\n",
    "from vingat.assertion import assert_package_versions\n",
    "from vingat.loader import (\n",
    "    core_file_loader, load_recipe_nutrients, load_ingredients,\n",
    "    load_recipe_ingredients, load_recipe_cooking_directions,\n",
    "    load_ingredients_with_embeddings, load_recipe_image_embeddings, load_recipe_image_embeddings_ft,\n",
    "    load_recipe_image_vlm_caption,\n",
    "    load_recipe_cooking_directions_embeddings,\n",
    "    load_recipe_image_vlm_caption_embeddings,\n",
    "    load_user_embeddings, load_alternative_ingredients,\n",
    "    train_dataclustering, calculate_cluster, load_clouster_centers)\n",
    "from vingat.loss import BPRLoss\n",
    "from vingat.model import RecommendationModel\n",
    "from vingat.functions import evaluate_model, save_model, train_func, get_item_popularity\n",
    "from vingat import __version__ as vingat_version\n",
    "from vingat.dataloader import create_base_hetero, mask_hetero, create_dataloader\n",
    "from vingat.visualizer import visualize_node_pca\n",
    "from vingat.preprocess import filter_recipe_ingredient\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "assert_package_versions() # assert versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv wandb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "wandab_api = os.getenv('WANDB_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from vingat.loader import use_nutritions\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "PROJECT_NAME = \"vingat-v3_local\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "CONFIG = {\n",
    "    \"architecture\": \"LightGCN, HGT, GAT\",\n",
    "    \"_mode\" : \"in_local\",\n",
    "    \"batch_size\": 256,\n",
    "    \"bprloss_reg_lambda\": 0.001,\n",
    "    \"cl_loss_rate\": 0.2,\n",
    "    \"cluster_margin\": 0.5,\n",
    "    \"cluster_loss_weight\": 1.2,\n",
    "    \"criterion\": \"\",\n",
    "    \"default_decay\": 0.00002,\n",
    "    \"device\": device,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"epochs\": 20,\n",
    "    \"filter_ingredient_sim_score\": 0.7,\n",
    "    \"fusion_gnn_after_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_dropout_rate\": 0.2,\n",
    "    \"fusion_gnn_resisual_alpha\": 0.5,\n",
    "    \"fusion_layers\": 1,\n",
    "    \"hidden_dimention\": 128,\n",
    "    \"image_encoder_low_rank_dim\": 64,\n",
    "    \"input_cooking_direction_dim\": 384,\n",
    "    \"input_image_dim\": 1024,\n",
    "    \"input_ingredient_dim\": 384,\n",
    "    \"input_vlm_caption_dim\": 384,\n",
    "    \"intention_cl_after_dropout_rate\": 0.2,\n",
    "    \"intention_layers\": 1,\n",
    "    \"item_encoder_dropout_rate\": 0.2,\n",
    "    \"item_encoder_low_rank_dim\": 64,\n",
    "    \"learning_rate\": 0.00002,\n",
    "    \"link_predictor_dropout_rate\": 0.2,\n",
    "    \"link_predictor_leaky_relu_slope\": 0.3,\n",
    "    \"max_grad_norm\": 30,\n",
    "    \"multi_head\": 1,\n",
    "    \"node_embeding_dimmention\": 32,\n",
    "    \"nutrient_dim\": 20,\n",
    "    \"patience\": 20,  #  Early stop at least, * validation_interval\n",
    "    \"pyg_lib v\": pyg_lib.__version__,\n",
    "    \"rating_threshold\": 3.5,\n",
    "    \"scheduler_gamma\": 0.975,\n",
    "    \"scheduler_size\": 10,\n",
    "    \"seed\": 2020,\n",
    "    \"sencing_layers\": 1,\n",
    "    \"sensing_gnn_resisual_alpha\": 0.5,\n",
    "    \"taste_gnn_after_dropout_rate\": 0.2,\n",
    "    \"taste_gnn_dropout_rate\": 0.2,\n",
    "    \"temperature\": 0.1,\n",
    "    \"torch v\": torch.__version__,\n",
    "    \"torch_geometric v\": torch_geometric.__version__,\n",
    "    \"torch_scatter v\": torch_scatter.__version__,\n",
    "    \"torch_sparse v\": torch_sparse.__version__,\n",
    "    \"user_encoder_dropout_rate\": 0.2,\n",
    "    \"user_encoder_low_rank_dim\": 64,\n",
    "    \"user_encoder_weight_decay\": 0.000001,\n",
    "    \"validation_interval\": 5,\n",
    "    \"vingat_v\": vingat_version,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "\n",
    "run_name = get_run_name()\n",
    "run_name = f\"{run_name}_{vingat_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\matsuoka\\_netrc\n",
      "wandb: Currently logged in as: ryu-2-24 (ryu-2-24-shiga-u-ac-jp) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\wandb\\run-20250319_080138-r6gkrwme</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/r6gkrwme' target=\"_blank\">run-20250319-080136_0.3.28</a></strong> to <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/r6gkrwme' target=\"_blank\">https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/r6gkrwme</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ryu-2-24-shiga-u-ac-jp/vingat-v3_local/runs/r6gkrwme?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2312a7e0e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=wandab_api)\n",
    "wandb.init(\n",
    "  project=PROJECT_NAME,\n",
    "  name=run_name,\n",
    "  config=CONFIG,\n",
    "  tags=[\"in_local\", \"use_mini_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n",
      "recipe_nutrients is loaded\n",
      "ingredients is loaded\n",
      "recipe_ingredients is loaded\n",
      "recipe_cooking_directions is loaded\n",
      "ingredients_with_embeddings is loaded\n",
      "recipe_image_embeddings_ft is loaded\n"
     ]
    }
   ],
   "source": [
    "PATH = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "\n",
    "# File loader\n",
    "core_recipes, core_train_rating, core_test_rating, core_val_rating = core_file_loader(PATH, CONFIG[\"rating_threshold\"])\n",
    "core_recipe_indices = core_recipes.index.values\n",
    "recipe_nutrients = load_recipe_nutrients(PATH, core_recipes.copy())\n",
    "ingredients = load_ingredients(PATH, core_recipes.copy())\n",
    "alternative_ingredients = load_alternative_ingredients(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_ingredients = load_recipe_ingredients(PATH, core_recipes.copy())\n",
    "recipe_cooking_directions = load_recipe_cooking_directions(PATH, core_recipes.copy())\n",
    "ingredients_with_embeddings = load_ingredients_with_embeddings(PATH, ingredients.copy())\n",
    "recipe_image_embeddings = load_recipe_image_embeddings_ft(PATH, core_recipes.copy(), CONFIG[\"device\"])\n",
    "recipe_image_vlm_caption = load_recipe_image_vlm_caption(PATH)\n",
    "recipe_cooking_directions_embeddings = load_recipe_cooking_directions_embeddings(PATH, recipe_cooking_directions.copy())\n",
    "recipe_ingredients = filter_recipe_ingredient(recipe_ingredients, alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "ingredients = ingredients[ingredients.index.isin(recipe_ingredients[\"ingredient_id\"])]\n",
    "recipe_image_vlm_caption_embeddings = load_recipe_image_vlm_caption_embeddings(PATH, recipe_image_vlm_caption.copy())\n",
    "\n",
    "train_nutrients, kmeans_model, scaler = train_dataclustering(\n",
    "    train_data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_train_rating.recipe_id)][use_nutritions],\n",
    "    n_cluster=6,\n",
    "    path=PATH\n",
    ")\n",
    "test_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_test_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "valid_nutrients = calculate_cluster(\n",
    "    data=recipe_nutrients.loc[recipe_nutrients.index.isin(core_val_rating.recipe_id)][use_nutritions],\n",
    "    path=PATH,\n",
    "    scaler=scaler,\n",
    "    kmeans_model=kmeans_model\n",
    ")\n",
    "recipe_nutrients = pd.concat([\n",
    "    train_nutrients, test_nutrients, valid_nutrients\n",
    "])\n",
    "recipe_nutrients = recipe_nutrients.loc[~recipe_nutrients.index.duplicated(keep='first')]\n",
    "recipe_cluster_centers = load_clouster_centers(kmeanth_model=kmeans_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmini_path = os.path.join(os.getcwd(), \\'..\\', \\'data\\', \\'mini\\')\\nmini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\\nmini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\\nmini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\\nuser_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\\nrecipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\\nmini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\\nmini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\\nmini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\\nmini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\\nmini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\\nmini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\\nmini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\\nmini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\\nmini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\\nmini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\\nmini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\\nmini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\\nmini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\\n\\ndiff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\\nmini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\\n\\nmini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\\nmini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\\nmini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\\nmini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\\nmini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\\nmini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\\nmini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\\nmini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\\nmini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\\nmini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\\nmini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\\nmini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\\nmini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\\nmini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create mini data\n",
    "\"\"\"\n",
    "mini_path = os.path.join(os.getcwd(), '..', 'data', 'mini')\n",
    "mini_core_train_rating = core_train_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_test_rating = core_test_rating.sample(frac=0.02, random_state=1)\n",
    "mini_core_val_rating = core_val_rating.sample(frac=0.02, random_state=1)\n",
    "user_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).user_id.unique()\n",
    "recipe_ids = pd.concat([mini_core_train_rating, mini_core_test_rating, mini_core_val_rating]).recipe_id.unique()\n",
    "mini_core_recipes = core_recipes.loc[core_recipes.index.isin(recipe_ids)]\n",
    "mini_recipe_ingredients = recipe_ingredients.loc[recipe_ingredients[\"recipe_id\"].isin(recipe_ids)]\n",
    "mini_ingredients = ingredients.loc[ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "mini_recipe_nutrients = recipe_nutrients.loc[recipe_nutrients.index.isin(recipe_ids)]\n",
    "mini_recipe_image_embeddings = recipe_image_embeddings.loc[recipe_image_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption_embeddings = recipe_image_vlm_caption_embeddings.loc[recipe_image_vlm_caption_embeddings.index.isin(recipe_ids)]\n",
    "mini_recipe_cooking_directions_embeddings = recipe_cooking_directions_embeddings.loc[recipe_cooking_directions_embeddings.index.isin(recipe_ids)]\n",
    "mini_ingredients_with_embeddings = ingredients_with_embeddings.loc[ingredients_with_embeddings.index.isin(mini_ingredients.index)]\n",
    "mini_recipe_cooking_directions = recipe_cooking_directions.loc[recipe_cooking_directions.index.isin(recipe_ids)]\n",
    "mini_recipe_image_vlm_caption = recipe_image_vlm_caption.loc[recipe_image_vlm_caption.index.isin(recipe_ids)]\n",
    "mini_alternative_ingredients = load_alternative_ingredients(mini_path, mini_core_recipes.copy(), CONFIG[\"device\"])\n",
    "mini_recipe_ingredients = filter_recipe_ingredient(mini_recipe_ingredients, mini_alternative_ingredients, CONFIG[\"filter_ingredient_sim_score\"])\n",
    "mini_ingredients = mini_ingredients[mini_ingredients.index.isin(mini_recipe_ingredients[\"ingredient_id\"])]\n",
    "\n",
    "diff_ing_id = list(set(mini_recipe_ingredients.ingredient_id) - set(mini_ingredients.index))\n",
    "mini_recipe_ingredients = mini_recipe_ingredients.loc[~mini_recipe_ingredients[\"ingredient_id\"].isin(diff_ing_id)]\n",
    "\n",
    "mini_core_train_rating.to_csv(os.path.join(mini_path, \"core-data-train_rating.csv\"))\n",
    "mini_core_test_rating.to_csv(os.path.join(mini_path, \"core-data-test_rating.csv\"))\n",
    "mini_core_val_rating.to_csv(os.path.join(mini_path, \"core-data-valid_rating.csv\"))\n",
    "mini_recipe_ingredients.to_csv(os.path.join(mini_path, \"recipe_ingredients.csv\"))\n",
    "mini_ingredients.to_csv(os.path.join(mini_path, \"ingredients.csv\"))\n",
    "mini_recipe_image_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_embeddings_ft.csv\"))\n",
    "mini_recipe_image_vlm_caption_embeddings.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption_embeddings.csv\"))\n",
    "mini_recipe_cooking_directions_embeddings.to_csv(os.path.join(mini_path, \"recipe_cooking_directions_embeddings.csv\"))\n",
    "mini_ingredients_with_embeddings.to_csv(os.path.join(mini_path, \"ingredients_embeddings.csv\"))\n",
    "mini_core_recipes.to_csv(os.path.join(mini_path, \"core-data_recipe.csv\"))\n",
    "mini_recipe_nutrients.to_csv(os.path.join(mini_path, \"recipe_nutrients.csv\"))\n",
    "mini_alternative_ingredients.to_csv(os.path.join(mini_path, \"alternative_ingredients.csv\"))\n",
    "mini_recipe_cooking_directions.to_csv(os.path.join(mini_path, \"recipe_cooking_directions.csv\"))\n",
    "mini_recipe_image_vlm_caption.to_csv(os.path.join(mini_path, \"recipe_image_vlm_caption.csv\"))\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一旦使わないけど： 3.5\n"
     ]
    }
   ],
   "source": [
    "data, user_lencoder, item_lencoder, ing_lencoder = create_base_hetero(\n",
    "    core_train_rating=core_train_rating,\n",
    "    core_test_rating=core_test_rating,\n",
    "    core_val_rating=core_val_rating,\n",
    "    ingredients=ingredients,\n",
    "    recipe_nutrients=recipe_nutrients,\n",
    "    recipe_image_embeddings=recipe_image_embeddings,\n",
    "    recipe_image_vlm_caption_embeddings=recipe_image_vlm_caption_embeddings,\n",
    "    recipe_cooking_directions_embeddings=recipe_cooking_directions_embeddings,\n",
    "    ingredients_with_embeddings=ingredients_with_embeddings,\n",
    "    directory_path=PATH,\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    ")\n",
    "\n",
    "train_data, ss = mask_hetero(data, core_train_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=True)\n",
    "test_data, _ = mask_hetero(data, core_test_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "val_data, _ = mask_hetero(data, core_val_rating, recipe_ingredients, user_lencoder, item_lencoder, ing_lencoder, is_train=False, scalar_preprocess=ss)\n",
    "\n",
    "mini_train = test_data.clone()\n",
    "pops = get_item_popularity(device, item_lencoder, PATH, CONFIG[\"rating_threshold\"])\n",
    "\n",
    "train_loader = create_dataloader(train_data, CONFIG[\"batch_size\"], num_workers=2, neg_sampling_ratio=1.0, popularity=pops, is_abration_cl=False)\n",
    "test_loader = create_dataloader(test_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n",
    "val_loader = create_dataloader(val_data, CONFIG[\"batch_size\"], shuffle=False, neg_sampling_ratio=0.0, is_abration_cl=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "データ構造\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4591e+00,  3.4127e-01, -2.4327e-01,  4.5590e-01,  4.3523e-01,\n",
       "          1.1508e+00,  1.8228e+00,  7.1900e-01,  1.8449e+00,  6.7767e-01,\n",
       "          1.8449e+00,  1.3193e+00,  1.1162e+00,  1.0711e+00,  1.5388e+00,\n",
       "          1.6623e+00,  9.8833e-02,  1.0520e+00,  1.7327e+00,  1.7917e-01],\n",
       "        [-6.6246e-01, -4.0594e-01, -2.2133e-01, -2.1434e-01, -4.7903e-01,\n",
       "         -6.3409e-01, -8.4808e-01, -3.5847e-01, -6.9371e-01, -4.1243e-01,\n",
       "         -6.9371e-01, -4.6745e-01, -6.5506e-01, -5.6926e-01, -6.2701e-01,\n",
       "         -7.2637e-01, -2.2268e-01, -6.6084e-01, -6.1469e-01, -2.6292e-01],\n",
       "        [ 6.1561e-01, -2.0697e-01, -4.4692e-01,  1.3882e-01, -3.9254e-01,\n",
       "          4.7435e-01,  1.9459e-01,  1.5163e-01,  2.5896e-01, -1.3396e-01,\n",
       "          2.5896e-01,  1.3665e-01,  1.5564e-01,  1.6888e-01,  4.8492e-01,\n",
       "          6.6342e-01, -1.1611e-01,  2.2462e-01,  1.7362e-01, -7.5989e-02],\n",
       "        [ 2.9614e-01,  1.7944e+00, -1.5653e-01,  1.4624e-01,  8.0766e-01,\n",
       "          8.7732e-01,  3.2829e-01,  4.6246e-01, -1.3299e-01,  1.3534e+00,\n",
       "         -1.3299e-01,  3.8469e-01,  1.3407e+00,  1.0164e+00, -2.7857e-01,\n",
       "          2.6761e-01,  1.0211e+00,  1.4540e+00, -2.6078e-01,  1.3081e+00],\n",
       "        [-5.1972e-01, -1.4978e-01,  1.7679e+00, -1.5225e-01,  1.1323e+00,\n",
       "         -5.8623e-01,  4.8960e-01, -1.4613e-01,  2.7874e-01, -1.6636e-01,\n",
       "          2.7874e-01, -1.9078e-01, -2.9820e-01, -2.7462e-01,  2.1007e-02,\n",
       "         -5.4999e-01, -3.7217e-02, -4.5189e-01,  3.9054e-01, -3.1474e-01],\n",
       "        [-2.4157e-01,  5.5776e+00,  9.5466e+00,  6.1911e+01,  6.7232e+00,\n",
       "          2.2167e+00,  1.8912e+00,  3.4972e+00, -1.1201e+00,  1.0621e+01,\n",
       "         -1.1201e+00,  3.6738e+00,  6.4743e+00,  3.9170e+00, -9.4720e-01,\n",
       "         -8.0389e-02,  1.9166e-01,  8.1403e+00, -1.0054e+00,  2.7496e+01]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\\n\\nデータ構造\")\n",
    "train_data\n",
    "recipe_cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = RecommendationModel(\n",
    "    dropout_rate=CONFIG[\"dropout_rate\"],\n",
    "    device=CONFIG[\"device\"],\n",
    "    hidden_dim=CONFIG[\"hidden_dimention\"],\n",
    "    node_embeding_dimmention=CONFIG[\"node_embeding_dimmention\"],\n",
    "    num_user=len(user_lencoder.classes_),\n",
    "    num_item=len(item_lencoder.classes_),\n",
    "    nutrient_dim=CONFIG[\"nutrient_dim\"],\n",
    "    num_heads=CONFIG[\"multi_head\"],\n",
    "    sencing_layers=CONFIG[\"sencing_layers\"],\n",
    "    fusion_layers=CONFIG[\"fusion_layers\"],\n",
    "    intention_layers=CONFIG[\"intention_layers\"],\n",
    "    temperature=CONFIG[\"temperature\"],\n",
    "    cl_loss_rate=CONFIG[\"cl_loss_rate\"],\n",
    "    input_image_dim=CONFIG[\"input_image_dim\"],\n",
    "    input_vlm_caption_dim=CONFIG[\"input_vlm_caption_dim\"],\n",
    "    input_ingredient_dim=CONFIG[\"input_ingredient_dim\"],\n",
    "    input_cooking_direction_dim=CONFIG[\"input_cooking_direction_dim\"],\n",
    "    user_encoder_low_rank_dim=CONFIG[\"user_encoder_low_rank_dim\"],\n",
    "    item_encoder_low_rank_dim=CONFIG[\"item_encoder_low_rank_dim\"],\n",
    "    user_encoder_dropout_rate=CONFIG[\"user_encoder_dropout_rate\"],\n",
    "    item_encoder_dropout_rate=CONFIG[\"item_encoder_dropout_rate\"],\n",
    "    intention_cl_after_dropout_rate=CONFIG[\"intention_cl_after_dropout_rate\"],\n",
    "    taste_gnn_dropout_rate=CONFIG[\"taste_gnn_dropout_rate\"],\n",
    "    taste_gnn_after_dropout_rate=CONFIG[\"taste_gnn_after_dropout_rate\"],\n",
    "    fusion_gnn_dropout_rate=CONFIG[\"fusion_gnn_dropout_rate\"],\n",
    "    fusion_gnn_after_dropout_rate=CONFIG[\"fusion_gnn_after_dropout_rate\"],\n",
    "    link_predictor_dropout_rate=CONFIG[\"link_predictor_dropout_rate\"],\n",
    "    link_predictor_leaky_relu_slope=CONFIG[\"link_predictor_leaky_relu_slope\"],\n",
    "    sensing_gnn_resisual_alpha=CONFIG[\"sensing_gnn_resisual_alpha\"],\n",
    "    fusion_gnn_resisual_alpha=CONFIG[\"fusion_gnn_resisual_alpha\"],\n",
    "    is_abration_wo_cl=False,\n",
    "    is_abration_wo_taste=False,\n",
    "    image_encoder_low_rank_dim=CONFIG[\"image_encoder_low_rank_dim\"],\n",
    "    cluster_centers=recipe_cluster_centers,\n",
    "    cluster_margin=CONFIG[\"cluster_margin\"],\n",
    "    cluster_loss_weight=CONFIG[\"cluster_loss_weight\"],\n",
    ")\n",
    "\n",
    "user_encoder_params = list(model.user_encoder.parameters())\n",
    "other_params = [\n",
    "    p for p in model.parameters()\n",
    "    if not any(torch.equal(p.data, up.data) for up in user_encoder_params)\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": user_encoder_params,\n",
    "            \"weight_decay\": CONFIG[\"user_encoder_weight_decay\"],\n",
    "        },\n",
    "        {\n",
    "            \"params\": other_params,\n",
    "            \"weight_decay\": CONFIG[\"default_decay\"],\n",
    "        }\n",
    "    ],\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    # weight_decay=CONFIG[\"default_decay\"],\n",
    ")\n",
    "\n",
    "# criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=CONFIG[\"scheduler_size\"],\n",
    "    gamma=CONFIG[\"scheduler_gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\matsuoka\\.conda\\envs\\gnnmf-cl\\lib\\site-packages (1.8.0)\n",
      "\n",
      "\n",
      "\n",
      "モデルの構造\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "RecommendationModel                           --\n",
      "├─Sequential: 1-1                             --\n",
      "│    └─Embedding: 2-1                         878,720\n",
      "│    └─Linear: 2-2                            8,320\n",
      "│    └─Dropout: 2-3                           --\n",
      "├─Sequential: 1-2                             --\n",
      "│    └─Embedding: 2-4                         655,424\n",
      "│    └─Linear: 2-5                            8,320\n",
      "│    └─Dropout: 2-6                           --\n",
      "├─LowRankLinear: 1-3                          --\n",
      "│    └─Linear: 2-7                            65,536\n",
      "│    └─Linear: 2-8                            8,320\n",
      "├─Linear: 1-4                                 49,280\n",
      "├─Linear: 1-5                                 49,280\n",
      "├─NutrientCaptionContrastiveLearning: 1-6     --\n",
      "│    └─Sequential: 2-9                        --\n",
      "│    │    └─Linear: 3-1                       1,344\n",
      "│    │    └─ReLU: 3-2                         --\n",
      "│    │    └─Linear: 3-3                       8,320\n",
      "│    └─Sequential: 2-10                       --\n",
      "│    │    └─Linear: 3-4                       98,560\n",
      "│    │    └─ReLU: 3-5                         --\n",
      "│    │    └─Linear: 3-6                       32,896\n",
      "│    └─ContrastiveLoss: 2-11                  --\n",
      "├─Sequential: 1-7                             --\n",
      "│    └─DictActivate: 2-12                     --\n",
      "│    └─DictDropout: 2-13                      --\n",
      "├─ModuleList: 1-8                             --\n",
      "│    └─TasteGNN: 2-14                         --\n",
      "│    │    └─HANConv: 3-7                      49,920\n",
      "├─Sequential: 1-9                             --\n",
      "│    └─DictActivate: 2-15                     --\n",
      "│    └─DictDropout: 2-16                      --\n",
      "├─ModuleList: 1-10                            --\n",
      "│    └─MultiModalFusionGAT: 2-17              --\n",
      "│    │    └─HGTConv: 3-8                      494,090\n",
      "├─Sequential: 1-11                            --\n",
      "│    └─DictActivate: 2-18                     --\n",
      "│    └─DictDropout: 2-19                      --\n",
      "├─Sequential: 1-12                            --\n",
      "│    └─Linear: 2-20                           32,896\n",
      "│    └─LeakyReLU: 2-21                        --\n",
      "│    └─Dropout: 2-22                          --\n",
      "│    └─Linear: 2-23                           129\n",
      "├─DictLayerNormForLayer: 1-13                 --\n",
      "│    └─ModuleDict: 2-24                       --\n",
      "│    │    └─LayerNorm: 3-9                    256\n",
      "│    │    └─LayerNorm: 3-10                   256\n",
      "│    │    └─LayerNorm: 3-11                   256\n",
      "│    │    └─LayerNorm: 3-12                   256\n",
      "│    │    └─LayerNorm: 3-13                   256\n",
      "│    │    └─LayerNorm: 3-14                   256\n",
      "│    └─ModuleDict: 2-25                       --\n",
      "│    │    └─Sequential: 3-15                  33,280\n",
      "│    │    └─Sequential: 3-16                  33,280\n",
      "│    │    └─Sequential: 3-17                  33,280\n",
      "│    │    └─Sequential: 3-18                  33,280\n",
      "│    │    └─Sequential: 3-19                  33,280\n",
      "│    │    └─Sequential: 3-20                  33,280\n",
      "======================================================================\n",
      "Total params: 2,642,571\n",
      "Trainable params: 2,642,571\n",
      "Non-trainable params: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "model_summary = summary(model, verbose=0)\n",
    "\n",
    "summary_text = str(model_summary)\n",
    "summary_text = summary_text.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "wandb.log({\"model_summary\": wandb.Html(summary_text)})\n",
    "print(\"\\n\\n\\nモデルの構造\")\n",
    "print(model_summary)\n",
    "\n",
    "wandb.watch(model, log=\"gradients\", log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      " Epoch 1/20 2025-03-19 08:01:54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc35221aea90438c8ad1f0b7f9c08026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Node Statics: \n",
      "                 min      max      mean       std  count  bin_0.0_rate  \\\n",
      "user        0.000000  0.00000  0.000000  0.000000   53.0       1.00000   \n",
      "item        0.000000  0.00000  0.000000  0.000000   53.0       1.00000   \n",
      "image       0.000000  0.00000  0.000000  0.000000   53.0       1.00000   \n",
      "intention   0.000000  0.00000  0.000000  0.000000   53.0       1.00000   \n",
      "taste      -0.001015  0.00161  0.000189  0.000574   53.0       0.09434   \n",
      "ingredient  0.000000  0.00000  0.000000  0.000000   53.0       1.00000   \n",
      "\n",
      "            bin_0.2_rate  bin_0.4_rate  bin_0.6_rate  bin_0.8_rate  \n",
      "user            0.000000      0.000000      0.000000      0.000000  \n",
      "item            0.000000      0.000000      0.000000      0.000000  \n",
      "image           0.000000      0.000000      0.000000      0.000000  \n",
      "intention       0.000000      0.000000      0.000000      0.000000  \n",
      "taste           0.377358      0.245283      0.226415      0.056604  \n",
      "ingredient      0.000000      0.000000      0.000000      0.000000  \n",
      "\n",
      "[Train] Loss:  \n",
      " {'train-loss/total_loss': np.float64(9.101645793554917), 'train-loss/main_loss': np.float64(0.9203798827135338), 'train-loss/xe_loss': np.float64(0.0), 'train-loss/cl_loss': np.float64(1.5902342189033076)}\n",
      "\n",
      "[Train] Metrics: \n",
      "{'train-handler/AUROC': 0.5, 'train-handler/accuracy': 0.5, 'train-handler/f1': 0.0, 'train-handler/ndcg@10': 0.4989, 'train-handler/precision@10': 0.4983, 'train-handler/recall': 0.0, 'train-handler/recall@10': 0.1913, 'train-handler/tn': 13539, 'train-handler/fp': 0, 'train-handler/fn': 13539, 'train-handler/tp': 0}\n",
      "\n",
      "[Train] Score Statics: \n",
      "{'train-score-statics/pos_mean': 0.5, 'train-score-statics/pos_min': 0.5, 'train-score-statics/pos_max': 0.5, 'train-score-statics/pos_std': 0.0, 'train-score-statics/neg_mean': 0.5, 'train-score-statics/neg_min': 0.5, 'train-score-statics/neg_max': 0.5, 'train-score-statics/neg_std': 0.0, 'train-score-statics/diff_mean': 0.0}\n",
      "\n",
      "[Train] Model Parameters: \n",
      "Model Parameters Describe: \n",
      "            param\n",
      "count  114.000000\n",
      "mean     3.983179\n",
      "std      5.289829\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%     10.985583\n",
      "max     17.249535\n",
      "Outer Value of Model Params (2σ): \n",
      "                                     name      param\n",
      "17  intention_cl.caption_encoder.0.weight  17.249535\n",
      "\n",
      "======================\n",
      " Epoch 2/20 2025-03-19 08:02:23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f489b1c2414d318ac6fcf6958c4624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Node Statics: \n",
      "                 min       max     mean      std  count  bin_0.0_rate  \\\n",
      "user        0.000000  0.000000  0.00000  0.00000   53.0      1.000000   \n",
      "item        0.000000  0.000000  0.00000  0.00000   53.0      1.000000   \n",
      "image       0.000000  0.000000  0.00000  0.00000   53.0      1.000000   \n",
      "intention   0.000000  0.000000  0.00000  0.00000   53.0      1.000000   \n",
      "taste      -0.001199  0.001368 -0.00002  0.00063   53.0      0.207547   \n",
      "ingredient  0.000000  0.000000  0.00000  0.00000   53.0      1.000000   \n",
      "\n",
      "            bin_0.2_rate  bin_0.4_rate  bin_0.6_rate  bin_0.8_rate  \n",
      "user            0.000000      0.000000      0.000000      0.000000  \n",
      "item            0.000000      0.000000      0.000000      0.000000  \n",
      "image           0.000000      0.000000      0.000000      0.000000  \n",
      "intention       0.000000      0.000000      0.000000      0.000000  \n",
      "taste           0.207547      0.339623      0.113208      0.132075  \n",
      "ingredient      0.000000      0.000000      0.000000      0.000000  \n",
      "\n",
      "[Train] Loss:  \n",
      " {'train-loss/total_loss': np.float64(9.063234059315807), 'train-loss/main_loss': np.float64(0.9153077366217127), 'train-loss/xe_loss': np.float64(0.0), 'train-loss/cl_loss': np.float64(1.583819920161985)}\n",
      "\n",
      "[Train] Metrics: \n",
      "{'train-handler/AUROC': 0.5, 'train-handler/accuracy': 0.5, 'train-handler/f1': 0.0, 'train-handler/ndcg@10': 0.5008, 'train-handler/precision@10': 0.4978, 'train-handler/recall': 0.0, 'train-handler/recall@10': 0.1951, 'train-handler/tn': 13539, 'train-handler/fp': 0, 'train-handler/fn': 13539, 'train-handler/tp': 0}\n",
      "\n",
      "[Train] Score Statics: \n",
      "{'train-score-statics/pos_mean': 0.5, 'train-score-statics/pos_min': 0.5, 'train-score-statics/pos_max': 0.5, 'train-score-statics/pos_std': 0.0, 'train-score-statics/neg_mean': 0.5, 'train-score-statics/neg_min': 0.5, 'train-score-statics/neg_max': 0.5, 'train-score-statics/neg_std': 0.0, 'train-score-statics/diff_mean': 0.0}\n",
      "\n",
      "[Train] Model Parameters: \n",
      "Model Parameters Describe: \n",
      "            param\n",
      "count  114.000000\n",
      "mean     3.927969\n",
      "std      5.223959\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%     10.777876\n",
      "max     16.966383\n",
      "Outer Value of Model Params (2σ): \n",
      "                                     name      param\n",
      "17  intention_cl.caption_encoder.0.weight  16.966383\n",
      "\n",
      "======================\n",
      " Epoch 3/20 2025-03-19 08:02:49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7633f66dc61448d5ad3628ee034e9e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Node Statics: \n",
      "                 min       max      mean       std  count  bin_0.0_rate  \\\n",
      "user        0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "item        0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "image       0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "intention   0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "taste      -0.001329  0.001919 -0.000128  0.000604   53.0      0.188679   \n",
      "ingredient  0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "\n",
      "            bin_0.2_rate  bin_0.4_rate  bin_0.6_rate  bin_0.8_rate  \n",
      "user            0.000000      0.000000      0.000000      0.000000  \n",
      "item            0.000000      0.000000      0.000000      0.000000  \n",
      "image           0.000000      0.000000      0.000000      0.000000  \n",
      "intention       0.000000      0.000000      0.000000      0.000000  \n",
      "taste           0.339623      0.396226      0.056604      0.018868  \n",
      "ingredient      0.000000      0.000000      0.000000      0.000000  \n",
      "\n",
      "[Train] Loss:  \n",
      " {'train-loss/total_loss': np.float64(9.02975436876405), 'train-loss/main_loss': np.float64(0.9103063221247691), 'train-loss/xe_loss': np.float64(0.0), 'train-loss/cl_loss': np.float64(1.5783743251044795)}\n",
      "\n",
      "[Train] Metrics: \n",
      "{'train-handler/AUROC': 0.5, 'train-handler/accuracy': 0.5, 'train-handler/f1': 0.0, 'train-handler/ndcg@10': 0.4979, 'train-handler/precision@10': 0.4976, 'train-handler/recall': 0.0, 'train-handler/recall@10': 0.19, 'train-handler/tn': 13539, 'train-handler/fp': 0, 'train-handler/fn': 13539, 'train-handler/tp': 0}\n",
      "\n",
      "[Train] Score Statics: \n",
      "{'train-score-statics/pos_mean': 0.5, 'train-score-statics/pos_min': 0.5, 'train-score-statics/pos_max': 0.5, 'train-score-statics/pos_std': 0.0, 'train-score-statics/neg_mean': 0.5, 'train-score-statics/neg_min': 0.5, 'train-score-statics/neg_max': 0.5, 'train-score-statics/neg_std': 0.0, 'train-score-statics/diff_mean': 0.0}\n",
      "\n",
      "[Train] Model Parameters: \n",
      "Model Parameters Describe: \n",
      "            param\n",
      "count  114.000000\n",
      "mean     3.873505\n",
      "std      5.159683\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%     10.572207\n",
      "max     16.685810\n",
      "Outer Value of Model Params (2σ): \n",
      "                                     name     param\n",
      "17  intention_cl.caption_encoder.0.weight  16.68581\n",
      "\n",
      "======================\n",
      " Epoch 4/20 2025-03-19 08:03:16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c70c6a1cdc43dd96c21b9325d95fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Node Statics: \n",
      "                 min       max      mean      std  count  bin_0.0_rate  \\\n",
      "user        0.000000  0.000000  0.000000  0.00000   53.0      1.000000   \n",
      "item        0.000000  0.000000  0.000000  0.00000   53.0      1.000000   \n",
      "image       0.000000  0.000000  0.000000  0.00000   53.0      1.000000   \n",
      "intention   0.000000  0.000000  0.000000  0.00000   53.0      1.000000   \n",
      "taste      -0.001597  0.000921 -0.000147  0.00054   53.0      0.056604   \n",
      "ingredient  0.000000  0.000000  0.000000  0.00000   53.0      1.000000   \n",
      "\n",
      "            bin_0.2_rate  bin_0.4_rate  bin_0.6_rate  bin_0.8_rate  \n",
      "user             0.00000      0.000000      0.000000      0.000000  \n",
      "item             0.00000      0.000000      0.000000      0.000000  \n",
      "image            0.00000      0.000000      0.000000      0.000000  \n",
      "intention        0.00000      0.000000      0.000000      0.000000  \n",
      "taste            0.09434      0.396226      0.320755      0.132075  \n",
      "ingredient       0.00000      0.000000      0.000000      0.000000  \n",
      "\n",
      "[Train] Loss:  \n",
      " {'train-loss/total_loss': np.float64(9.002476026427072), 'train-loss/main_loss': np.float64(0.905371090151229), 'train-loss/xe_loss': np.float64(0.0), 'train-loss/cl_loss': np.float64(1.5741524583888504)}\n",
      "\n",
      "[Train] Metrics: \n",
      "{'train-handler/AUROC': 0.5, 'train-handler/accuracy': 0.5, 'train-handler/f1': 0.0, 'train-handler/ndcg@10': 0.4996, 'train-handler/precision@10': 0.4996, 'train-handler/recall': 0.0, 'train-handler/recall@10': 0.1933, 'train-handler/tn': 13539, 'train-handler/fp': 0, 'train-handler/fn': 13539, 'train-handler/tp': 0}\n",
      "\n",
      "[Train] Score Statics: \n",
      "{'train-score-statics/pos_mean': 0.5, 'train-score-statics/pos_min': 0.5, 'train-score-statics/pos_max': 0.5, 'train-score-statics/pos_std': 0.0, 'train-score-statics/neg_mean': 0.5, 'train-score-statics/neg_min': 0.5, 'train-score-statics/neg_max': 0.5, 'train-score-statics/neg_std': 0.0, 'train-score-statics/diff_mean': 0.0}\n",
      "\n",
      "[Train] Model Parameters: \n",
      "Model Parameters Describe: \n",
      "            param\n",
      "count  114.000000\n",
      "mean     3.819749\n",
      "std      5.096867\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%     10.368472\n",
      "max     16.407700\n",
      "Outer Value of Model Params (2σ): \n",
      "                                     name    param\n",
      "17  intention_cl.caption_encoder.0.weight  16.4077\n",
      "\n",
      "======================\n",
      " Epoch 5/20 2025-03-19 08:03:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb70797b58dc46ea84d20fc88084902b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Train]:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Node Statics: \n",
      "                 min       max      mean       std  count  bin_0.0_rate  \\\n",
      "user        0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "item        0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "image       0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "intention   0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "taste      -0.001262  0.001423 -0.000258  0.000566   53.0      0.188679   \n",
      "ingredient  0.000000  0.000000  0.000000  0.000000   53.0      1.000000   \n",
      "\n",
      "            bin_0.2_rate  bin_0.4_rate  bin_0.6_rate  bin_0.8_rate  \n",
      "user            0.000000      0.000000      0.000000      0.000000  \n",
      "item            0.000000      0.000000      0.000000      0.000000  \n",
      "image           0.000000      0.000000      0.000000      0.000000  \n",
      "intention       0.000000      0.000000      0.000000      0.000000  \n",
      "taste           0.396226      0.264151      0.113208      0.037736  \n",
      "ingredient      0.000000      0.000000      0.000000      0.000000  \n",
      "\n",
      "[Train] Loss:  \n",
      " {'train-loss/total_loss': np.float64(8.977596157001999), 'train-loss/main_loss': np.float64(0.9005009599451749), 'train-loss/xe_loss': np.float64(0.0), 'train-loss/cl_loss': np.float64(1.5703940099140383)}\n",
      "\n",
      "[Train] Metrics: \n",
      "{'train-handler/AUROC': 0.5, 'train-handler/accuracy': 0.5, 'train-handler/f1': 0.0, 'train-handler/ndcg@10': 0.5015, 'train-handler/precision@10': 0.5005, 'train-handler/recall': 0.0, 'train-handler/recall@10': 0.1952, 'train-handler/tn': 13539, 'train-handler/fp': 0, 'train-handler/fn': 13539, 'train-handler/tp': 0}\n",
      "\n",
      "[Train] Score Statics: \n",
      "{'train-score-statics/pos_mean': 0.5, 'train-score-statics/pos_min': 0.5, 'train-score-statics/pos_max': 0.5, 'train-score-statics/pos_std': 0.0, 'train-score-statics/neg_mean': 0.5, 'train-score-statics/neg_min': 0.5, 'train-score-statics/neg_max': 0.5, 'train-score-statics/neg_std': 0.0, 'train-score-statics/diff_mean': 0.0}\n",
      "\n",
      "[Train] Model Parameters: \n",
      "Model Parameters Describe: \n",
      "            param\n",
      "count  114.000000\n",
      "mean     3.766748\n",
      "std      5.035447\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%     10.166806\n",
      "max     16.132217\n",
      "Outer Value of Model Params (2σ): \n",
      "                                     name      param\n",
      "17  intention_cl.caption_encoder.0.weight  16.132217\n",
      "\n",
      "Validation -------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b3c6afb96f4025bc7a78929eabd487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Valid] Epoch 5/20:   0%|          | 0/2193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m pca_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintention\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaste\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m BPRLoss(reg_lambda\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbprloss_reg_lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m train_func(\n\u001b[0;32m     34\u001b[0m     train_loader,\n\u001b[0;32m     35\u001b[0m     val_data,\n\u001b[0;32m     36\u001b[0m     model,\n\u001b[0;32m     37\u001b[0m     optimizer,\n\u001b[0;32m     38\u001b[0m     scheduler,\n\u001b[0;32m     39\u001b[0m     criterion,\n\u001b[0;32m     40\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     42\u001b[0m     wbLogger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[0;32m     43\u001b[0m     wbTagger\u001b[38;5;241m=\u001b[39mwandb_tagger,\n\u001b[0;32m     44\u001b[0m     wbScatter\u001b[38;5;241m=\u001b[39mwandb_scatter,\n\u001b[0;32m     45\u001b[0m     directory_path\u001b[38;5;241m=\u001b[39mPATH,\n\u001b[0;32m     46\u001b[0m     project_name\u001b[38;5;241m=\u001b[39mPROJECT_NAME,\n\u001b[0;32m     47\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m     48\u001b[0m     popularities\u001b[38;5;241m=\u001b[39mpops,\n\u001b[0;32m     49\u001b[0m     patience\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     50\u001b[0m     validation_interval\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_interval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     51\u001b[0m     max_grad_norm\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_grad_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     52\u001b[0m     pca_cols\u001b[38;5;241m=\u001b[39mpca_cols,\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:372\u001b[0m, in \u001b[0;36mtrain_func\u001b[1;34m(train_loader, val_data, model, optimizer, scheduler, criterion, epochs, device, wbLogger, wbTagger, wbScatter, directory_path, project_name, experiment_name, popularities, patience, validation_interval, max_grad_norm, pca_cols)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValidation -------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m_df = visualize_node_pca(batch_data,\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m                         pca_cols,\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m                         f\"after_training. Epoch: {epoch}/{epochs}\")\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mwbScatter(_df, epoch, title=f\"after training (epoch: {epoch})\")\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m score_statics, v_mhandler \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[0;32m    373\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    374\u001b[0m     data\u001b[38;5;241m=\u001b[39mval_data,\n\u001b[0;32m    375\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    376\u001b[0m     freq_tensor\u001b[38;5;241m=\u001b[39mpopularities,\n\u001b[0;32m    377\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Valid] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    378\u001b[0m )\n\u001b[0;32m    380\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval/last_lr\u001b[39m\u001b[38;5;124m\"\u001b[39m: scheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    382\u001b[0m }\n\u001b[0;32m    384\u001b[0m wbLogger(\n\u001b[0;32m    385\u001b[0m     data\u001b[38;5;241m=\u001b[39mval_metrics,\n\u001b[0;32m    386\u001b[0m     step\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m    387\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\functions.py:89\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, data, device, freq_tensor, desc)\u001b[0m\n\u001b[0;32m     79\u001b[0m         mhandler\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m     80\u001b[0m             probas\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat([pos_scores, neg_scores]),\n\u001b[0;32m     81\u001b[0m             targets\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                     user_id, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     87\u001b[0m         )\n\u001b[0;32m     88\u001b[0m     shandler\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m---> 89\u001b[0m     mhandler\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shandler, mhandler\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\Git\\GNNMF-CL\\notebook\\..\\vingat\\metrics.py:131\u001b[0m, in \u001b[0;36mMetricsHandler.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m all_user_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_indices)\n\u001b[0;32m    113\u001b[0m collection \u001b[38;5;241m=\u001b[39m MetricCollection({\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall@10\u001b[39m\u001b[38;5;124m\"\u001b[39m: RetrievalRecall(top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# \"recall@20\": RetrievalRecall(top_k=20),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC\u001b[39m\u001b[38;5;124m\"\u001b[39m: BinaryAUROC(),\n\u001b[0;32m    129\u001b[0m })\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 131\u001b[0m result \u001b[38;5;241m=\u001b[39m collection(all_probas, all_targets, indexes\u001b[38;5;241m=\u001b[39mall_user_indices)\n\u001b[0;32m    132\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcm\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    133\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcm\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\collections.py:230\u001b[0m, in \u001b[0;36mMetricCollection.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call forward for each metric sequentially.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    Positional arguments (args) will be passed to every metric in the collection, while keyword arguments (kwargs)\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    will be filtered based on the signature of the individual metric.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_and_reduce(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\collections.py:379\u001b[0m, in \u001b[0;36mMetricCollection._compute_and_reduce\u001b[1;34m(self, method_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m     res \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 379\u001b[0m     res \u001b[38;5;241m=\u001b[39m m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mm\u001b[38;5;241m.\u001b[39m_filter_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod_name should be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\metric.py:315\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\metric.py:385\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 385\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_count \u001b[38;5;241m=\u001b[39m _update_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\metric.py:699\u001b[0m, in \u001b[0;36mMetric._wrap_compute.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;66;03m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# if synchronization happened, the current rank accumulated states will be restored to keep\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# accumulation going if ``should_unsync=True``,\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_context(\n\u001b[0;32m    695\u001b[0m     dist_sync_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_sync_fn,\n\u001b[0;32m    696\u001b[0m     should_sync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_sync,\n\u001b[0;32m    697\u001b[0m     should_unsync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_unsync,\n\u001b[0;32m    698\u001b[0m ):\n\u001b[1;32m--> 699\u001b[0m     value \u001b[38;5;241m=\u001b[39m _squeeze_if_scalar(compute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;66;03m# clone tensor to avoid in-place operations after compute, altering already computed results\u001b[39;00m\n\u001b[0;32m    701\u001b[0m     value \u001b[38;5;241m=\u001b[39m apply_to_collection(value, Tensor, \u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mclone())\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\retrieval\\base.py:179\u001b[0m, in \u001b[0;36mRetrievalMetric.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m             res\u001b[38;5;241m.\u001b[39mappend(tensor(\u001b[38;5;241m0.0\u001b[39m))\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;66;03m# ensure list contains only float tensors\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric(mini_preds, mini_target))\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _retrieval_aggregate(torch\u001b[38;5;241m.\u001b[39mstack([x\u001b[38;5;241m.\u001b[39mto(preds) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m res]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregation)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\retrieval\\ndcg.py:120\u001b[0m, in \u001b[0;36mRetrievalNormalizedDCG._metric\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_metric\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retrieval_normalized_dcg(preds, target, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\functional\\retrieval\\ndcg.py:105\u001b[0m, in \u001b[0;36mretrieval_normalized_dcg\u001b[1;34m(preds, target, top_k)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(top_k, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m top_k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`top_k` has to be a positive integer or None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m gain \u001b[38;5;241m=\u001b[39m _dcg_sample_scores(target, preds, top_k, ignore_ties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m normalized_gain \u001b[38;5;241m=\u001b[39m _dcg_sample_scores(target, target, top_k, ignore_ties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# filter undefined scores\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\functional\\retrieval\\ndcg.py:67\u001b[0m, in \u001b[0;36m_dcg_sample_scores\u001b[1;34m(target, preds, top_k, ignore_ties)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     discount_cumsum \u001b[38;5;241m=\u001b[39m discount\u001b[38;5;241m.\u001b[39mcumsum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m     cumulative_gain \u001b[38;5;241m=\u001b[39m _tie_average_dcg(target, preds, discount_cumsum)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cumulative_gain\n",
      "File \u001b[1;32mc:\\Users\\matsuoka\\.conda\\envs\\GNNMF-CL\\Lib\\site-packages\\torchmetrics\\functional\\retrieval\\ndcg.py:35\u001b[0m, in \u001b[0;36m_tie_average_dcg\u001b[1;34m(target, preds, discount_cumsum)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Translated version of sklearns `_tie_average_dcg` function.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m _, inv, counts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;241m-\u001b[39mpreds, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 35\u001b[0m ranked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(counts, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     36\u001b[0m ranked\u001b[38;5;241m.\u001b[39mscatter_add_(\u001b[38;5;241m0\u001b[39m, inv, target\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mranked\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m     37\u001b[0m ranked \u001b[38;5;241m=\u001b[39m ranked \u001b[38;5;241m/\u001b[39m counts\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def wandb_logger(**kwargs):\n",
    "    try:\n",
    "        wandb.log(**kwargs)\n",
    "    except:\n",
    "        print(kwargs)\n",
    "        pass\n",
    "\n",
    "def wandb_tagger(*args):\n",
    "    try:\n",
    "        wandb.run.tags = list(wandb.run.tags) + list(args)\n",
    "    except:\n",
    "        print(args)\n",
    "        pass\n",
    "\n",
    "def wandb_scatter(df, step, title):\n",
    "    df[\"step\"] = step\n",
    "    table = wandb.Table(data=df, columns=[\"PC1\", \"PC2\", \"node_type\"])\n",
    "    color_cahrt = wandb.plot.scatter(\n",
    "        table,\n",
    "        \"PC1\",\n",
    "        \"PC2\",\n",
    "        title=title,\n",
    "    )\n",
    "    wandb.run.log({f\"scatter_step_{step}\": color_cahrt},\n",
    "                step=step)\n",
    "\n",
    "\n",
    "pca_cols = [\"intention\", \"taste\", \"image\"]\n",
    "\n",
    "criterion = BPRLoss(reg_lambda=CONFIG[\"bprloss_reg_lambda\"])\n",
    "\n",
    "\n",
    "train_func(\n",
    "    train_loader,\n",
    "    val_data,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    epochs=CONFIG[\"epochs\"],\n",
    "    device=device,\n",
    "    wbLogger=wandb_logger,\n",
    "    wbTagger=wandb_tagger,\n",
    "    wbScatter=wandb_scatter,\n",
    "    directory_path=PATH,\n",
    "    project_name=PROJECT_NAME,\n",
    "    experiment_name=run_name,\n",
    "    popularities=pops,\n",
    "    patience=CONFIG[\"patience\"],\n",
    "    validation_interval=CONFIG[\"validation_interval\"],\n",
    "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
    "    pca_cols=pca_cols,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_statics, t_mhandler = evaluate_model(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    device=CONFIG[\"device\"],\n",
    "    freq_tensor=pops,\n",
    "    desc=\"[Test]\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Score Statics: \")\n",
    "print(score_statics.log(prefix=\"test-score-statics\", num_round=4))\n",
    "wandb_logger(data=score_statics.log(prefix=\"test-score-statics\"))\n",
    "\n",
    "print(\"handler Result: \")\n",
    "print(t_mhandler.log(prefix=\"test-handler\", num_round=4))\n",
    "wandb_logger(data=t_mhandler.log(prefix=\"test-handler\", num_round=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config[\"criterion\"] = str(criterion.__class__.__name__)\n",
    "wandb.run.tags = list(wandb.run.tags) + [\"image_fine_tuned\"]\n",
    "\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"crashed\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"all_same_result\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"manual_stopped\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"over_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_learning\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"not_satisfied\"]\n",
    "#wandb.run.tags = list(wandb.run.tags) + [\"is_trial_model\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNMF-CL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
